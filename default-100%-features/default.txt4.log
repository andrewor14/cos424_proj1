preprocessSentences.py:68: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  return [clean_word(w) for w in tokens if w.lower() not in stop_words and w.isalpha()]
Path: .
Training data: ./default.txt4.train
Done building things up man. Num documents in train set: 2400.
Number of features before any feature selection: 11200
Number of features after filtering out words by count threshold: 489
Done doing the feature selection thing man. Num vocabs: 489.
Output files: ./out*
Runtime: 4.00573396683
Running model 'mybnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
Num train examples = 2400, positive prior = 0.458333333333, negative prior = 0.541666666667
Using 489 features: second, dialogu, unit, music, relat, hold, want, beauti, fit, wast...
459 features are used in positive reviews: forget, lack, month, abil, go, follow, tv, friendli, send, certainli...
463 features are used in negative reviews: forget, lack, month, abil, go, follow, hate, tv, friendli, send...
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  positive probability = 5.16867100289e-67, negative probability = 1.13560184716e-65
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  positive probability = 0.000831820931639, negative probability = 0.00249615975422
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  positive probability = 2.13647644583e-19, negative probability = 2.49844715642e-18
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  positive probability = 1.16167975567e-43, negative probability = 1.53565550437e-44
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  positive probability = 4.73786577185e-14, negative probability = 5.79078153316e-15
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  positive probability = 1.02744341871e-09, negative probability = 4.41745020816e-08
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  positive probability = 9.39418491438e-37, negative probability = 7.68668536417e-37
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  positive probability = 3.22088194817e-63, negative probability = 6.09469870813e-62
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  positive probability = 3.48674642124e-30, negative probability = 1.70049091905e-30
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  positive probability = 2.36311986304e-08, negative probability = 4.74139655676e-07
  predicted label = 0, expected label = 0

================================
You guessed 435/600 = 72.5% correct.
  - False positive rate: [0.0, 0.48, 1.0]
  - True positive rate: [0.0, 0.8275, 1.0]
  - Thresholds: [2, 1, 0]
  - AUC: 0.67375
  - F1: 0.800483675937
================================

Running model 'mymnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
Num train examples = 2400, positive prior = 0.458333333333, negative prior = 0.541666666667
Using 489 features: second, dialogu, unit, music, relat, hold, want, beauti, fit, wast...
459 features are used in positive reviews: forget, lack, month, abil, go, follow, tv, friendli, send, certainli...
463 features are used in negative reviews: forget, lack, month, abil, go, follow, hate, tv, friendli, send...
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  positive probability = 5.87198608713e-71, negative probability = 5.71692788487e-69
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  positive probability = 0.000576882735473, negative probability = 0.00181665735048
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  positive probability = 1.6485494938e-20, negative probability = 3.3136921656e-19
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  positive probability = 7.93588727807e-46, negative probability = 1.30708387132e-46
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  positive probability = 7.60100886655e-15, negative probability = 1.18233460017e-15
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  positive probability = 3.42713337649e-10, negative probability = 1.75960032335e-08
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  positive probability = 8.06508909792e-39, negative probability = 1.27782308301e-38
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  positive probability = 7.8287879615e-67, negative probability = 5.42903082027e-65
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  positive probability = 6.93799706696e-32, negative probability = 5.52397962512e-32
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  positive probability = 7.88240676592e-09, negative probability = 1.82771388425e-07
  predicted label = 0, expected label = 0

================================
You guessed 423/600 = 70.5% correct.
  - False positive rate: [0.0, 0.405, 1.0]
  - True positive rate: [0.0, 0.76, 1.0]
  - Thresholds: [2, 1, 0]
  - AUC: 0.6775
  - F1: 0.774522292994
================================

Running model 'bnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.206751869796, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.188770958457, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.0283199296143, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 0.347325834567, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 0.778717050616, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0132755453999, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.15812230291, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.010216026626, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 0.275442941742, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0274655708844, expected label = 0

================================
You guessed 399/600 = 66.5% correct.
  - False positive rate: [0.0, 0.0, 0.005, 0.005, 0.005, 0.005, 0.01, 0.01, 0.015, 0.015, 0.015, 0.015, 0.02, 0.02, 0.02, 0.02, 0.02, 0.025, 0.025, 0.025, 0.025, 0.03, 0.03, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.045, 0.045, 0.045, 0.05, 0.05, 0.05, 0.05, 0.055, 0.055, 0.06, 0.06, 0.065, 0.065, 0.07, 0.07, 0.075, 0.075, 0.075, 0.08, 0.08, 0.085, 0.085, 0.09, 0.09, 0.095, 0.095, 0.1, 0.1, 0.105, 0.105, 0.105, 0.105, 0.115, 0.115, 0.115, 0.115, 0.12, 0.12, 0.135, 0.14, 0.145, 0.145, 0.15, 0.15, 0.15, 0.16, 0.16, 0.165, 0.165, 0.17, 0.17, 0.18, 0.18, 0.185, 0.185, 0.195, 0.195, 0.205, 0.205, 0.205, 0.205, 0.21, 0.21, 0.215, 0.215, 0.22, 0.22, 0.22, 0.235, 0.235, 0.285, 0.29, 0.29, 0.295, 0.295, 0.31, 0.31, 0.34, 0.355, 0.36, 0.36, 0.36, 0.375, 0.375, 0.385, 0.385, 0.39, 0.39, 0.395, 0.395, 0.4, 0.4, 0.41, 0.41, 0.42, 0.425, 0.425, 0.43, 0.43, 0.435, 0.435, 0.445, 0.445, 0.445, 0.455, 0.455, 0.46, 0.46, 0.475, 0.475, 0.48, 0.48, 0.49, 0.495, 0.5, 0.5, 0.51, 0.51, 0.52, 0.52, 0.53, 0.53, 0.54, 0.54, 0.54, 0.545, 0.555, 0.565, 0.565, 0.575, 0.585, 0.585, 0.59, 0.59, 0.595, 0.595, 0.61, 0.61, 0.625, 0.625, 0.64, 0.64, 0.645, 0.645, 0.65, 0.65, 0.655, 0.655, 0.67, 0.67, 0.69, 0.69, 0.7, 0.7, 0.705, 0.705, 0.725, 0.725, 0.73, 0.73, 0.75, 0.75, 0.755, 0.755, 0.77, 0.77, 0.79, 0.79, 0.815, 0.815, 0.845, 0.845, 0.85, 0.86, 0.865, 0.865, 0.895, 0.895, 0.91, 0.91, 0.92, 0.925, 0.94, 0.94, 0.945, 0.945, 0.96, 0.96, 1.0]
  - True positive rate: [0.0025, 0.06, 0.06, 0.0925, 0.0975, 0.1025, 0.1025, 0.125, 0.125, 0.145, 0.1625, 0.17, 0.17, 0.175, 0.1975, 0.2125, 0.2175, 0.2175, 0.23, 0.235, 0.2375, 0.2375, 0.275, 0.275, 0.2775, 0.2825, 0.2925, 0.3, 0.31, 0.325, 0.3275, 0.3275, 0.33, 0.335, 0.335, 0.3525, 0.3575, 0.375, 0.375, 0.385, 0.385, 0.3875, 0.39, 0.4, 0.4025, 0.41, 0.425, 0.4325, 0.445, 0.4475, 0.45, 0.45, 0.4525, 0.4525, 0.4575, 0.4575, 0.46, 0.46, 0.465, 0.465, 0.4975, 0.5025, 0.515, 0.515, 0.5225, 0.5325, 0.535, 0.535, 0.56, 0.56, 0.5625, 0.5625, 0.5725, 0.5725, 0.575, 0.58, 0.58, 0.585, 0.585, 0.5875, 0.5875, 0.5975, 0.5975, 0.6025, 0.6025, 0.6075, 0.6075, 0.615, 0.615, 0.62, 0.6225, 0.63, 0.63, 0.635, 0.635, 0.6375, 0.6375, 0.6425, 0.645, 0.645, 0.65, 0.72, 0.72, 0.7275, 0.7275, 0.7325, 0.7325, 0.7375, 0.7375, 0.7375, 0.7375, 0.7425, 0.7525, 0.7525, 0.755, 0.755, 0.76, 0.7625, 0.765, 0.765, 0.7725, 0.7725, 0.775, 0.775, 0.7775, 0.7775, 0.78, 0.785, 0.785, 0.79, 0.79, 0.7975, 0.7975, 0.8, 0.81, 0.81, 0.815, 0.815, 0.8225, 0.8225, 0.8275, 0.8275, 0.83, 0.83, 0.835, 0.835, 0.85, 0.85, 0.855, 0.855, 0.8575, 0.8575, 0.86, 0.86, 0.87, 0.88, 0.88, 0.88, 0.88, 0.89, 0.895, 0.895, 0.8975, 0.8975, 0.9025, 0.9025, 0.915, 0.915, 0.92, 0.92, 0.9225, 0.9225, 0.9275, 0.9275, 0.93, 0.93, 0.9325, 0.9325, 0.935, 0.935, 0.9375, 0.9375, 0.94, 0.94, 0.9425, 0.9425, 0.9475, 0.9475, 0.95, 0.95, 0.9525, 0.9525, 0.955, 0.955, 0.9575, 0.9575, 0.96, 0.96, 0.965, 0.965, 0.97, 0.97, 0.9725, 0.9725, 0.98, 0.98, 0.9825, 0.9825, 0.985, 0.985, 0.9875, 0.9875, 0.99, 0.99, 0.995, 0.995, 0.9975, 0.9975, 1.0, 1.0]
  - Thresholds: [0.9992675050527479, 0.975425719259695, 0.9751566352719508, 0.9600488886624835, 0.9596718236785415, 0.9587866742819822, 0.9574242187906521, 0.9371750548728598, 0.9354113683600707, 0.9225361709166735, 0.9218005152185104, 0.9151720211242231, 0.9125419261251999, 0.9107614435485165, 0.8939215531136001, 0.8934307894438517, 0.890290658507234, 0.8853604261506889, 0.8788874231743801, 0.8759181555397233, 0.8757070526189049, 0.8752852986771182, 0.8379554682698034, 0.8316561647172933, 0.8273759787292789, 0.8244240825318463, 0.8139345758280756, 0.8099129485010046, 0.801172361275666, 0.7937509575233243, 0.7923994849819156, 0.7914880320270443, 0.7860285701495134, 0.7822693765265395, 0.7787170506158011, 0.7614903937061429, 0.7554365326445427, 0.7333075587285779, 0.7317670715715585, 0.7156332047099718, 0.7144315371762853, 0.7127880241787077, 0.7121543548094055, 0.685587666419026, 0.67829192373871, 0.6606186491524993, 0.6544648932359266, 0.6377769266297629, 0.6370769620784006, 0.6336347052820008, 0.6301069103980907, 0.6292480725143322, 0.6285424098062359, 0.628253717523524, 0.6144189819624696, 0.6107927924437355, 0.6089539459767809, 0.602660100184972, 0.5954324676969535, 0.5937089876611367, 0.5738833175842416, 0.5728653271831337, 0.5576369282283958, 0.5511824656831551, 0.542702756794578, 0.5390366529319863, 0.5367208902502069, 0.527561864165372, 0.4988956414864775, 0.48344301179837906, 0.48310901106616266, 0.4718240537770472, 0.4599444038955623, 0.4585112769230046, 0.4575140014688039, 0.4573437226354056, 0.45590771583137635, 0.4528404117885122, 0.45158599361565527, 0.4514263298511087, 0.4509884912805353, 0.44261464687669105, 0.44256781342266627, 0.44104455182064634, 0.4366631529451595, 0.42783104145614476, 0.41848634108504534, 0.41250445483655496, 0.41195207784063614, 0.4082412596571841, 0.40810609664610387, 0.40639284695732825, 0.4046379098068149, 0.3910644607223248, 0.39080697782332013, 0.3892719692586212, 0.38743749724164384, 0.3838725791405279, 0.3831303930689458, 0.37381637782817717, 0.3727857642193, 0.3720631182097555, 0.3706368091708152, 0.362181697106701, 0.36180219984185735, 0.3576581640751393, 0.34732583456675165, 0.34419970854564974, 0.32616482782168754, 0.32439916498088855, 0.3240920287068467, 0.3195026809924001, 0.31798466263376063, 0.31474518013755753, 0.31407842938057595, 0.3135898943687488, 0.3026638618842535, 0.2970978589332855, 0.2959764252542634, 0.29484702475788765, 0.29202345845360367, 0.2917828663033469, 0.2764487258102733, 0.2753213011208544, 0.2672724077585082, 0.26530348964669004, 0.2607929668500675, 0.2582636489080816, 0.25818271608235627, 0.24985506769200477, 0.24979548404310742, 0.24285233218961072, 0.24147381401622475, 0.241314346761287, 0.23994441033695907, 0.2391310201228217, 0.23670470124484577, 0.23097057347850353, 0.22904333753679074, 0.2275544123851182, 0.2215385151304966, 0.22064820684897649, 0.22022456013231356, 0.21687722988426505, 0.21383449617986036, 0.21379843320458913, 0.20694048118152858, 0.20675186979556673, 0.2016726992370895, 0.19832300501723094, 0.19437971178869198, 0.19332160810496202, 0.19204841202392203, 0.18877095845675687, 0.17687663722807118, 0.17639034572612802, 0.17530357141232178, 0.1728505252932774, 0.1686905654324975, 0.16241031038196949, 0.16152714970040777, 0.1591536363419318, 0.15832055524467392, 0.15812230290989868, 0.15710604719978533, 0.15210743235687157, 0.13003311844946486, 0.1272331658704034, 0.12489352652387764, 0.11758037792432215, 0.11690179062596609, 0.11343096411575619, 0.11263520039189402, 0.11224445388281333, 0.11083432275195498, 0.10948612174854136, 0.10792297898532824, 0.1050366386231628, 0.10242136081265904, 0.10017799865409678, 0.09939549916167335, 0.09687223519918987, 0.0948608592691849, 0.09017452440593758, 0.08997150818707568, 0.08951378333198803, 0.0844987341024204, 0.07276570469910984, 0.06706940774527367, 0.066998490445294, 0.06605913460957084, 0.05825077378798968, 0.05696280655295553, 0.0553339021537543, 0.05389655732930577, 0.048405718725052366, 0.04666931143418339, 0.04310627055365491, 0.04153078777576084, 0.034044569065686925, 0.031515207760216706, 0.027465570884394035, 0.02615413445469684, 0.025562319056733625, 0.02478339609900626, 0.024174252255525795, 0.024145718510759123, 0.018922518407064628, 0.01790521421718503, 0.014776346242343124, 0.013569493405700668, 0.013561756232150739, 0.013406359464161069, 0.012621198038591777, 0.010471403990805197, 0.010216026626016284, 0.009521224013547285, 0.00801686732313245, 0.007853269149340076, 0.00016602485723396518]
  - AUC: 0.78411875
  - F1: 0.689335394127
================================

Running model 'mnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.00105830888893, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.230988023234, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.0255349971412, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 0.568815626803, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 0.801211231039, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0152420609863, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.148088774597, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.00176725265844, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 0.291650916058, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0331369716394, expected label = 0

================================
You guessed 400/600 = 66.6666666667% correct.
  - False positive rate: [0.0, 0.0, 0.005, 0.005, 0.01, 0.01, 0.01, 0.01, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.02, 0.02, 0.02, 0.02, 0.025, 0.025, 0.025, 0.025, 0.03, 0.03, 0.035, 0.035, 0.035, 0.035, 0.035, 0.035, 0.035, 0.04, 0.04, 0.04, 0.045, 0.045, 0.045, 0.045, 0.05, 0.05, 0.05, 0.055, 0.055, 0.06, 0.06, 0.065, 0.065, 0.07, 0.07, 0.075, 0.075, 0.075, 0.075, 0.08, 0.08, 0.085, 0.085, 0.095, 0.095, 0.095, 0.095, 0.095, 0.095, 0.1, 0.1, 0.105, 0.105, 0.11, 0.11, 0.12, 0.12, 0.125, 0.125, 0.14, 0.14, 0.14, 0.14, 0.145, 0.145, 0.16, 0.16, 0.165, 0.17, 0.17, 0.22, 0.22, 0.225, 0.225, 0.23, 0.23, 0.23, 0.24, 0.255, 0.255, 0.27, 0.27, 0.27, 0.275, 0.275, 0.285, 0.285, 0.285, 0.29, 0.305, 0.305, 0.315, 0.315, 0.325, 0.325, 0.325, 0.34, 0.34, 0.355, 0.355, 0.365, 0.365, 0.37, 0.375, 0.375, 0.38, 0.38, 0.39, 0.39, 0.395, 0.395, 0.4, 0.4, 0.41, 0.41, 0.415, 0.415, 0.415, 0.415, 0.425, 0.43, 0.44, 0.44, 0.445, 0.445, 0.45, 0.45, 0.455, 0.455, 0.46, 0.46, 0.465, 0.465, 0.48, 0.49, 0.49, 0.495, 0.495, 0.505, 0.52, 0.52, 0.53, 0.54, 0.54, 0.545, 0.545, 0.555, 0.555, 0.56, 0.56, 0.57, 0.57, 0.58, 0.58, 0.59, 0.59, 0.595, 0.595, 0.6, 0.6, 0.605, 0.605, 0.615, 0.615, 0.625, 0.625, 0.63, 0.63, 0.645, 0.645, 0.67, 0.67, 0.68, 0.68, 0.685, 0.685, 0.72, 0.72, 0.725, 0.725, 0.735, 0.735, 0.75, 0.75, 0.755, 0.755, 0.77, 0.77, 0.78, 0.78, 0.8, 0.8, 0.81, 0.81, 0.815, 0.825, 0.835, 0.835, 0.845, 0.845, 0.87, 0.87, 0.88, 0.885, 0.89, 0.9, 0.9, 0.91, 0.91, 0.915, 0.915, 0.925, 0.925, 1.0]
  - True positive rate: [0.0025, 0.05, 0.05, 0.0675, 0.0675, 0.0775, 0.0825, 0.0925, 0.0925, 0.13, 0.145, 0.1625, 0.1675, 0.1775, 0.1925, 0.1925, 0.2, 0.205, 0.2325, 0.2325, 0.2525, 0.2575, 0.27, 0.27, 0.275, 0.275, 0.28, 0.2875, 0.2925, 0.2975, 0.305, 0.3075, 0.3075, 0.315, 0.32, 0.32, 0.33, 0.335, 0.3375, 0.3375, 0.345, 0.35, 0.35, 0.36, 0.3625, 0.37, 0.37, 0.3775, 0.38, 0.3875, 0.4025, 0.4175, 0.4325, 0.45, 0.45, 0.4525, 0.455, 0.4625, 0.4625, 0.4675, 0.4725, 0.475, 0.48, 0.4875, 0.5, 0.5025, 0.5025, 0.505, 0.505, 0.5075, 0.5075, 0.5175, 0.5175, 0.5325, 0.5325, 0.56, 0.565, 0.5675, 0.5675, 0.575, 0.575, 0.595, 0.5975, 0.5975, 0.6, 0.67, 0.6725, 0.6725, 0.675, 0.675, 0.68, 0.685, 0.685, 0.685, 0.69, 0.69, 0.6925, 0.6975, 0.6975, 0.7, 0.7, 0.7025, 0.7075, 0.7075, 0.7125, 0.715, 0.715, 0.7225, 0.7225, 0.73, 0.735, 0.735, 0.7375, 0.7375, 0.74, 0.74, 0.745, 0.745, 0.75, 0.7525, 0.7525, 0.7575, 0.7575, 0.76, 0.7625, 0.77, 0.77, 0.7725, 0.7725, 0.775, 0.775, 0.78, 0.79, 0.7925, 0.7925, 0.7975, 0.7975, 0.8075, 0.8075, 0.81, 0.81, 0.8175, 0.8175, 0.82, 0.82, 0.825, 0.825, 0.8275, 0.8275, 0.8275, 0.8325, 0.8325, 0.8375, 0.8475, 0.8475, 0.86, 0.865, 0.865, 0.8775, 0.8775, 0.8825, 0.8825, 0.8875, 0.8875, 0.9, 0.9, 0.9025, 0.9025, 0.905, 0.905, 0.9075, 0.9075, 0.91, 0.91, 0.9125, 0.9125, 0.915, 0.915, 0.9175, 0.9175, 0.9225, 0.9225, 0.925, 0.925, 0.93, 0.93, 0.9325, 0.9325, 0.9425, 0.9425, 0.945, 0.945, 0.9475, 0.9475, 0.95, 0.95, 0.9525, 0.9525, 0.955, 0.955, 0.9575, 0.9575, 0.96, 0.96, 0.9625, 0.9625, 0.965, 0.965, 0.9675, 0.9675, 0.975, 0.975, 0.9775, 0.9775, 0.98, 0.98, 0.9825, 0.9825, 0.9825, 0.985, 0.985, 0.99, 0.99, 0.995, 0.995, 0.9975, 0.9975, 1.0, 1.0]
  - Thresholds: [0.999930756361872, 0.9837573206996559, 0.9837150654381424, 0.9725787701529353, 0.9713984489174127, 0.9692890772066647, 0.9674655147118358, 0.9622459424274218, 0.9620267870937637, 0.9354562658359395, 0.9334733217352092, 0.9228547484696404, 0.9219480080177, 0.9153497566283725, 0.9126856510255756, 0.9076111818204925, 0.9012383331665214, 0.9001108363565679, 0.8839684083635235, 0.8812869880715309, 0.8573289130139934, 0.8572936628663028, 0.8435594229347353, 0.8424561088997787, 0.8407133555664122, 0.8365097651135857, 0.8335217081191818, 0.8321049787629748, 0.8275318779661067, 0.8259167546508356, 0.8252531977937697, 0.8226787269083885, 0.8225903928291944, 0.81761358309699, 0.8141205675468353, 0.8115454270127157, 0.8101641053047856, 0.8076853754536533, 0.8048025836665148, 0.8012112310385483, 0.7832602880066266, 0.7830432655524825, 0.782818246469572, 0.7600073426614568, 0.7592614281338399, 0.738215494762281, 0.7355581381805197, 0.7310585914189862, 0.7299726653091947, 0.7116728295884917, 0.7113830332687606, 0.6926527711519312, 0.6925700939955587, 0.6649478756943205, 0.6574485125308491, 0.6417462878535615, 0.6374170726469005, 0.6267766178514368, 0.6219407257439761, 0.616797751057386, 0.6152945030786159, 0.6129127766713539, 0.6116398842816579, 0.6042808970708654, 0.6002956728551873, 0.5963367342504644, 0.5955249328253751, 0.5920916479832518, 0.5879035896461771, 0.5844745260465896, 0.5825382552828724, 0.5713658965296368, 0.5688156268033456, 0.5592293802968789, 0.5457600131459286, 0.5240822901453631, 0.5195383367825613, 0.5150566188450674, 0.5121839711325911, 0.49912253523655686, 0.49069618733324616, 0.4762857799974253, 0.4739913977224631, 0.4732710115307621, 0.459997028985238, 0.45833333333333326, 0.4564272834262204, 0.4539925557510312, 0.4523600107253805, 0.448916279382066, 0.4443504445144465, 0.4433991913731766, 0.4426649140551987, 0.44086313999869237, 0.4405484408237942, 0.43389940181006503, 0.43215245227051097, 0.4288731992989557, 0.4284178839306116, 0.42699308633584604, 0.4153751723644994, 0.4127964495780822, 0.4101643026480795, 0.4081920523832259, 0.40328154396699456, 0.395972321947886, 0.39269481515162274, 0.3791428853636857, 0.3757496224340849, 0.3752888230824679, 0.368868008571994, 0.363548270544262, 0.3615278943781425, 0.3509299495492957, 0.34956497820775123, 0.3395372619256772, 0.3288021461520661, 0.326011248520096, 0.3242409023430231, 0.32424090234302255, 0.32407393579509586, 0.3225894421133549, 0.31890806240051434, 0.31847626221149045, 0.3153344460991369, 0.3086939425880171, 0.30243543839383197, 0.29542595948514827, 0.2916509160580514, 0.28932739846544303, 0.28705026966009556, 0.28551652673365213, 0.2814991386914306, 0.28024380338265853, 0.27859808128043156, 0.27656223913798794, 0.2709700274260851, 0.2616868944196148, 0.26157598774336954, 0.2606875571014507, 0.25886330904052113, 0.2567644390400851, 0.254095139046116, 0.2525689751021819, 0.2514676895062478, 0.24422290732418034, 0.24364336362578876, 0.2409114410900862, 0.23573926266484618, 0.23098802323406234, 0.22477203419541725, 0.22106616389644174, 0.21460921787153064, 0.21280475590068687, 0.2110668336989313, 0.20474600195145998, 0.20019721242072427, 0.19727533532601343, 0.18328102410262379, 0.183272881839148, 0.18031785772082695, 0.1746406360564466, 0.17091552408373067, 0.17059953533266448, 0.1559766963982652, 0.15303867587592396, 0.15273582325193802, 0.148088774596596, 0.1450573371172877, 0.14302337589523625, 0.1407279245847897, 0.13554860464712118, 0.1317527610735021, 0.12864364581250623, 0.128269837324869, 0.12690869420501796, 0.12210033721194695, 0.11404848682917341, 0.11224624329790182, 0.11164308765300883, 0.10961905341630071, 0.10955189742550415, 0.1094128344123751, 0.10884187514562116, 0.10050698473651834, 0.09323205874515447, 0.09229905073481395, 0.08948347904935215, 0.08400261891077257, 0.08181691781518613, 0.08042210979855657, 0.07155604722566763, 0.07119050657780548, 0.07037346232910238, 0.06943090319680818, 0.06377754156849794, 0.060795650714397444, 0.054860181830220185, 0.05457897012509437, 0.05339858070944535, 0.05331573577104006, 0.049186203345831014, 0.04649011830849857, 0.04455693275319316, 0.0442160866315822, 0.03699092269855935, 0.03609370702560312, 0.034389055972694656, 0.034383067121686955, 0.03313697163939878, 0.032296550442989465, 0.030996315131133895, 0.027269269592607576, 0.025464301782498148, 0.0242342467565713, 0.019365599424407406, 0.01747252759395756, 0.016604694733290994, 0.0163893165360433, 0.015761233888295152, 0.015242060986332105, 0.014001217792108327, 0.011710068654160025, 0.010196078888653799, 0.010158607924126106, 0.009277762334837687, 0.007952188578272899, 0.007683597536992712, 2.2831851777379426e-06]
  - AUC: 0.78546875
  - F1: 0.696048632219
================================

Running model 'dt' on train data 'default.txt4.train' and test data 'default.txt4.test'
Best hyperparameters were: {'max_features': 'auto', 'min_samples_leaf': 1}
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.367441860465, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.166666666667, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0, expected label = 0

================================
You guessed 399/600 = 66.5% correct.
  - False positive rate: [0.0, 0.245, 0.245, 0.245, 0.245, 0.25, 0.26, 0.295, 0.3, 0.34, 0.42, 0.44, 0.445, 0.475, 0.48, 1.0]
  - True positive rate: [0.0, 0.4875, 0.54, 0.5475, 0.5625, 0.565, 0.5675, 0.6275, 0.64, 0.6675, 0.76, 0.765, 0.765, 0.7675, 0.7675, 1.0]
  - Thresholds: [2.0, 1.0, 0.967741935483871, 0.875, 0.8333333333333334, 0.8, 0.7894736842105263, 0.75, 0.6666666666666666, 0.5, 0.3674418604651163, 0.3333333333333333, 0.25, 0.16666666666666666, 0.14285714285714285, 0.0]
  - AUC: 0.68098125
  - F1: 0.726530612245
================================

Running model 'rf' on train data 'default.txt4.train' and test data 'default.txt4.test'
Best hyperparameters were: {'n_estimators': 10}
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.571075422858, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.36620320079, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.0534941753538, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 0.326644254639, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 0.40625306833, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.0694010347543, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.0393392207582, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 0.303718549399, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0822007176552, expected label = 0

================================
You guessed 353/600 = 58.8333333333% correct.
  - False positive rate: [0.0, 0.0, 0.0, 0.0, 0.0, 0.005, 0.005, 0.01, 0.035, 0.035, 0.04, 0.04, 0.045, 0.045, 0.05, 0.095, 0.105, 0.11, 0.11, 0.125, 0.125, 0.125, 0.13, 0.14, 0.15, 0.155, 0.155, 0.16, 0.16, 0.16, 0.165, 0.165, 0.175, 0.175, 0.18, 0.18, 0.19, 0.19, 0.195, 0.195, 0.2, 0.205, 0.205, 0.21, 0.21, 0.21, 0.225, 0.245, 0.245, 0.25, 0.25, 0.26, 0.26, 0.265, 0.27, 0.27, 0.27, 0.28, 0.28, 0.285, 0.285, 0.29, 0.505, 0.51, 0.51, 0.52, 0.525, 0.525, 0.53, 0.565, 0.57, 0.57, 0.58, 0.585, 0.59, 0.6, 0.6, 0.615, 0.615, 0.62, 0.62, 0.63, 0.64, 0.64, 0.65, 0.66, 0.665, 0.665, 0.665, 0.68, 0.695, 0.72, 0.725, 0.725, 0.73, 0.73, 0.74, 0.75, 0.75, 0.755, 0.76, 0.76, 0.77, 0.77, 0.775, 0.775, 0.785, 0.785, 0.805, 0.805, 0.81, 0.81, 0.825, 0.825, 0.83, 0.86, 0.86, 0.865, 0.865, 0.865, 0.87, 0.87, 0.88, 0.88, 0.885, 0.89, 0.895, 0.905, 0.91, 0.93, 0.935, 0.96, 0.965, 0.965, 0.97, 0.98, 1.0]
  - True positive rate: [0.0175, 0.02, 0.1325, 0.1375, 0.1425, 0.1925, 0.2075, 0.2275, 0.265, 0.2725, 0.2725, 0.2825, 0.285, 0.295, 0.295, 0.425, 0.425, 0.4325, 0.435, 0.435, 0.4375, 0.4425, 0.445, 0.445, 0.4475, 0.4475, 0.455, 0.455, 0.46, 0.465, 0.465, 0.47, 0.47, 0.48, 0.48, 0.485, 0.485, 0.4875, 0.49, 0.4925, 0.4975, 0.4975, 0.5025, 0.5025, 0.5075, 0.51, 0.515, 0.5225, 0.53, 0.535, 0.5375, 0.5375, 0.5425, 0.545, 0.545, 0.5475, 0.5575, 0.5575, 0.5625, 0.5625, 0.5675, 0.5675, 0.775, 0.775, 0.7775, 0.78, 0.78, 0.785, 0.785, 0.805, 0.805, 0.8075, 0.8075, 0.81, 0.815, 0.815, 0.82, 0.82, 0.8225, 0.8225, 0.8275, 0.8325, 0.835, 0.8375, 0.84, 0.845, 0.845, 0.85, 0.855, 0.8625, 0.8625, 0.8825, 0.885, 0.8875, 0.8875, 0.89, 0.89, 0.8925, 0.895, 0.895, 0.9, 0.9025, 0.9025, 0.91, 0.9175, 0.92, 0.92, 0.925, 0.925, 0.9325, 0.9325, 0.935, 0.935, 0.9375, 0.9375, 0.96, 0.9625, 0.9675, 0.9725, 0.975, 0.975, 0.9775, 0.9825, 0.985, 0.985, 0.9875, 0.9875, 0.9875, 0.9875, 0.9975, 0.9975, 0.9975, 0.9975, 1.0, 1.0, 1.0, 1.0]
  - Thresholds: [0.9790742121992123, 0.9449484952816561, 0.9441914165357741, 0.9427142704934106, 0.9374606473050051, 0.9309134075623581, 0.8724503133382164, 0.8723225703324807, 0.8684503133382163, 0.8373488496136545, 0.8360054347826086, 0.7516821829469881, 0.7437299650751308, 0.7261387263773897, 0.7119282195636876, 0.7014825270719749, 0.6874746116536675, 0.6756151239308463, 0.6727213510370735, 0.610483222037015, 0.6097960071935494, 0.5945794589697937, 0.5906915558513609, 0.5821905314888188, 0.5727689700846925, 0.5710754228584162, 0.5394786816122412, 0.5385698358855583, 0.5354372896604752, 0.5229591916129775, 0.5129528612643065, 0.5073190521864988, 0.5048416130541071, 0.47047243934941213, 0.4699240715110837, 0.4696784563272617, 0.4659753194057343, 0.4518061648496431, 0.4486805729731874, 0.44752558835234596, 0.4438883048863448, 0.4421737693749649, 0.4411038647112734, 0.4397459885010869, 0.4370051430788662, 0.4364884368739702, 0.43540051666526536, 0.43022217897727744, 0.4087761817013028, 0.40625306832968, 0.40356440515187353, 0.402476202630886, 0.39863629117239147, 0.39853972391632825, 0.3935268106611246, 0.39031003527463015, 0.38980956568438807, 0.38897869118240613, 0.37847529055190227, 0.3783120663428191, 0.3677671764743688, 0.3664488540012202, 0.3662032007903314, 0.36103533091843165, 0.35963053755139573, 0.3482763715220388, 0.3461539245353268, 0.3369002229654404, 0.3366327779118027, 0.336432901341883, 0.3331586671782796, 0.3328231166388588, 0.3291042870173305, 0.32664425463866, 0.32414900990309986, 0.31865303644700826, 0.31559066927875606, 0.30753152930176275, 0.30389999142316954, 0.30371854939898224, 0.29670802612643976, 0.28819736517468353, 0.2843998845357541, 0.28425723288011423, 0.27982533384494623, 0.27726340109387027, 0.2771970509343337, 0.2683538191821585, 0.2639002064908733, 0.2630885062215395, 0.2527309335614027, 0.2515657862273151, 0.24832556324256222, 0.24563032445285513, 0.24539574142046866, 0.24385577723591773, 0.23950596402293206, 0.23715687702535843, 0.23678317753166295, 0.23495813676347735, 0.22978662329795513, 0.21816269037979566, 0.20981111948447598, 0.2053644588749778, 0.20517345400392312, 0.20199280987025672, 0.1926004616940888, 0.1920992700424485, 0.1775322847087553, 0.17349328754220056, 0.15633434376081434, 0.15102047622223708, 0.13955932161630774, 0.13845410463151148, 0.13519875685900384, 0.13085637873928146, 0.1289577317503618, 0.12214732286259553, 0.11947333018860284, 0.11815237406833376, 0.1169351202291287, 0.10500446571973839, 0.10407250537642435, 0.0918898993163699, 0.08974840075383553, 0.08326737935977066, 0.08287878787878787, 0.08220071765519972, 0.07376511691633174, 0.07225878011220635, 0.06940103475429563, 0.053494175353828576, 0.04470046082949308, 0.04086259009532667, 0.03933922075822924, 0.0035714285714285713, 0.0]
  - AUC: 0.7134
  - F1: 0.603531300161
================================

