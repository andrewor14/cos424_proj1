preprocessSentences.py:68: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  return [clean_word(w) for w in tokens if w.lower() not in stop_words and w.isalpha()]
Path: .
Training data: ./default.txt4.train
Done building things up man. Num documents in train set: 2400.
Number of features before any feature selection: 11200
Number of features after filtering out words by count threshold: 489
Done doing the feature selection thing man. Num vocabs: 440.
Output files: ./out*
Runtime: 3.62548804283
Running model 'mybnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
Num train examples = 2400, positive prior = 0.458333333333, negative prior = 0.541666666667
Using 440 features: dialogu, unit, music, relat, hold, want, beauti, fit, wast, came...
411 features are used in positive reviews: forget, lack, abil, go, follow, tv, friendli, send, certainli, worth...
415 features are used in negative reviews: forget, lack, poorli, abil, go, follow, hate, tv, friendli, send...
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  positive probability = 1.03373420058e-67, negative probability = 1.89266974526e-66
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  positive probability = 0.000831820931639, negative probability = 0.00249615975422
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  positive probability = 2.13647644583e-19, negative probability = 2.49844715642e-18
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  positive probability = 2.90419938918e-44, negative probability = 3.07131100874e-45
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  positive probability = 4.73786577185e-14, negative probability = 5.79078153316e-15
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  positive probability = 1.02744341871e-09, negative probability = 4.41745020816e-08
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  positive probability = 9.39418491438e-37, negative probability = 7.68668536417e-37
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  positive probability = 1.07362731606e-64, negative probability = 1.64721586706e-63
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  positive probability = 3.48674642124e-30, negative probability = 1.70049091905e-30
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  positive probability = 2.36311986304e-08, negative probability = 4.74139655676e-07
  predicted label = 0, expected label = 0

================================
You guessed 434/600 = 72.3333333333% correct.
  - False positive rate: [0.0, 0.49, 1.0]
  - True positive rate: [0.0, 0.83, 1.0]
  - Thresholds: [2, 1, 0]
  - AUC: 0.67
  - F1: 0.8
================================

Running model 'mymnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
Num train examples = 2400, positive prior = 0.458333333333, negative prior = 0.541666666667
Using 440 features: dialogu, unit, music, relat, hold, want, beauti, fit, wast, came...
411 features are used in positive reviews: forget, lack, abil, go, follow, tv, friendli, send, certainli, worth...
415 features are used in negative reviews: forget, lack, poorli, abil, go, follow, hate, tv, friendli, send...
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  positive probability = 2.56977099451e-71, negative probability = 1.90782603324e-69
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  positive probability = 0.000595238095238, negative probability = 0.00186781609195
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  positive probability = 2.05269405699e-20, negative probability = 4.02475832147e-19
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  positive probability = 3.17382622737e-46, negative probability = 3.9650606587e-47
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  positive probability = 8.88970032493e-15, negative probability = 1.35845688897e-15
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  positive probability = 3.76478808761e-10, negative probability = 1.91248179583e-08
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  positive probability = 1.21185445122e-38, negative probability = 1.83343251386e-38
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  positive probability = 4.87588716925e-68, negative probability = 2.70609994877e-66
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  positive probability = 9.79194695146e-32, negative probability = 7.49763135564e-32
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  positive probability = 8.6590126015e-09, negative probability = 1.98651334922e-07
  predicted label = 0, expected label = 0

================================
You guessed 427/600 = 71.1666666667% correct.
  - False positive rate: [0.0, 0.41, 1.0]
  - True positive rate: [0.0, 0.7725, 1.0]
  - Thresholds: [2, 1, 0]
  - AUC: 0.68125
  - F1: 0.781289506953
================================

Running model 'bnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.209794983083, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.18920577673, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.0283981000416, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 0.36091435716, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 0.779205511592, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0133127583282, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.158500317922, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.0107025014148, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 0.27600947641, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0275414499004, expected label = 0

================================
You guessed 400/600 = 66.6666666667% correct.
  - False positive rate: [0.0, 0.0, 0.005, 0.005, 0.01, 0.01, 0.015, 0.015, 0.015, 0.015, 0.02, 0.02, 0.02, 0.02, 0.02, 0.025, 0.025, 0.025, 0.03, 0.03, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.045, 0.045, 0.045, 0.05, 0.05, 0.05, 0.05, 0.055, 0.055, 0.06, 0.06, 0.065, 0.065, 0.07, 0.07, 0.075, 0.075, 0.075, 0.08, 0.08, 0.085, 0.085, 0.095, 0.095, 0.1, 0.1, 0.105, 0.105, 0.105, 0.105, 0.115, 0.115, 0.115, 0.115, 0.12, 0.12, 0.125, 0.125, 0.13, 0.14, 0.145, 0.145, 0.15, 0.15, 0.15, 0.16, 0.16, 0.165, 0.165, 0.17, 0.17, 0.175, 0.175, 0.185, 0.185, 0.185, 0.19, 0.19, 0.195, 0.195, 0.2, 0.2, 0.205, 0.205, 0.205, 0.205, 0.21, 0.21, 0.215, 0.215, 0.215, 0.22, 0.22, 0.295, 0.3, 0.3, 0.305, 0.305, 0.315, 0.315, 0.335, 0.35, 0.355, 0.355, 0.355, 0.37, 0.37, 0.375, 0.375, 0.38, 0.38, 0.39, 0.39, 0.395, 0.395, 0.415, 0.415, 0.42, 0.425, 0.425, 0.435, 0.435, 0.445, 0.445, 0.455, 0.455, 0.46, 0.46, 0.465, 0.47, 0.47, 0.49, 0.495, 0.5, 0.5, 0.505, 0.505, 0.51, 0.51, 0.52, 0.52, 0.53, 0.54, 0.54, 0.545, 0.55, 0.56, 0.565, 0.565, 0.575, 0.585, 0.585, 0.59, 0.59, 0.595, 0.595, 0.605, 0.605, 0.62, 0.62, 0.63, 0.63, 0.635, 0.635, 0.64, 0.64, 0.66, 0.66, 0.685, 0.685, 0.69, 0.69, 0.7, 0.7, 0.705, 0.705, 0.73, 0.73, 0.735, 0.735, 0.75, 0.75, 0.755, 0.755, 0.775, 0.775, 0.79, 0.79, 0.815, 0.815, 0.845, 0.845, 0.85, 0.86, 0.865, 0.865, 0.895, 0.895, 0.905, 0.91, 0.92, 0.94, 0.94, 0.945, 0.945, 0.965, 0.965, 1.0]
  - True positive rate: [0.0025, 0.06, 0.06, 0.0875, 0.095, 0.125, 0.125, 0.145, 0.165, 0.17, 0.17, 0.175, 0.195, 0.21, 0.215, 0.215, 0.2325, 0.2375, 0.2375, 0.2725, 0.2725, 0.275, 0.2825, 0.2925, 0.3, 0.3175, 0.3325, 0.335, 0.335, 0.3375, 0.3425, 0.3425, 0.355, 0.36, 0.375, 0.375, 0.385, 0.385, 0.3875, 0.39, 0.3975, 0.4, 0.41, 0.425, 0.4325, 0.445, 0.4475, 0.45, 0.45, 0.4525, 0.4525, 0.46, 0.46, 0.465, 0.465, 0.4975, 0.505, 0.515, 0.515, 0.52, 0.53, 0.535, 0.535, 0.5625, 0.5625, 0.565, 0.565, 0.5675, 0.5675, 0.5775, 0.5775, 0.58, 0.585, 0.585, 0.5875, 0.5875, 0.59, 0.59, 0.595, 0.595, 0.6, 0.6, 0.6025, 0.6075, 0.6075, 0.6125, 0.6125, 0.615, 0.615, 0.6175, 0.6175, 0.62, 0.625, 0.6325, 0.6325, 0.6375, 0.6375, 0.6425, 0.645, 0.645, 0.65, 0.7275, 0.7275, 0.73, 0.73, 0.735, 0.735, 0.74, 0.74, 0.74, 0.74, 0.745, 0.7525, 0.7525, 0.755, 0.755, 0.76, 0.7625, 0.765, 0.765, 0.77, 0.77, 0.7725, 0.7725, 0.775, 0.775, 0.7775, 0.79, 0.79, 0.795, 0.795, 0.8075, 0.8075, 0.82, 0.82, 0.8225, 0.825, 0.825, 0.83, 0.83, 0.8375, 0.8375, 0.8425, 0.8425, 0.8475, 0.8475, 0.85, 0.85, 0.86, 0.86, 0.86, 0.8725, 0.885, 0.885, 0.885, 0.885, 0.89, 0.895, 0.895, 0.8975, 0.8975, 0.905, 0.905, 0.915, 0.915, 0.92, 0.92, 0.9225, 0.9225, 0.925, 0.925, 0.9275, 0.9275, 0.93, 0.93, 0.9375, 0.9375, 0.94, 0.94, 0.9425, 0.9425, 0.945, 0.945, 0.9475, 0.9475, 0.95, 0.95, 0.9525, 0.9525, 0.955, 0.955, 0.9575, 0.9575, 0.96, 0.96, 0.9675, 0.9675, 0.97, 0.97, 0.9725, 0.9725, 0.98, 0.98, 0.9825, 0.9825, 0.985, 0.985, 0.9875, 0.9875, 0.9875, 0.9925, 0.9925, 0.9975, 0.9975, 1.0, 1.0]
  - Thresholds: [0.9992695786156071, 0.9754936294830339, 0.9752252702133777, 0.9601575565625721, 0.9597814742380121, 0.9373418794547304, 0.9365174467846185, 0.922738662783533, 0.9220047675225429, 0.9153919975477415, 0.9127680728253152, 0.9109917451106776, 0.8941902650730107, 0.893700596747835, 0.8905674420908352, 0.8856480504937608, 0.8768948497386586, 0.8762261581240217, 0.875594649058373, 0.8383403121953407, 0.8320529705967746, 0.8277807842956412, 0.8248343448109161, 0.8143638295397339, 0.8103493183257017, 0.7970685485138453, 0.7942150023476692, 0.7928657770252937, 0.7919558337912703, 0.7865053164781117, 0.7827521836952113, 0.779205511591813, 0.7620052591567663, 0.7559602783381719, 0.7338619993126997, 0.7323235457213881, 0.7162101694496406, 0.7150099690905584, 0.7133684494968416, 0.7127355446139034, 0.686198860968413, 0.6789106584721574, 0.6635110656392476, 0.6551061526632395, 0.638432046384343, 0.637732628708513, 0.6342930209106372, 0.63076787117421, 0.629909666572907, 0.6292045210717538, 0.62190862721069, 0.6096292877858052, 0.6033392313326037, 0.5998702121295214, 0.5943931212222674, 0.5745769136404167, 0.5735593489566474, 0.5609329038847326, 0.5518841595008389, 0.5410428270536423, 0.5397414792223578, 0.5365232463220612, 0.5282688812060367, 0.4996048676476411, 0.49214014491514607, 0.4891181368929267, 0.48415149478243263, 0.48381746302707995, 0.4725310855140571, 0.4606491596971448, 0.45921570402039463, 0.4582181929511165, 0.4580478733236439, 0.4566115159461931, 0.4535434238789751, 0.45228866804655576, 0.45212896066354846, 0.4516910017376092, 0.4464991938271418, 0.4438235169789934, 0.4433146460668833, 0.4432677974484726, 0.4417763359135687, 0.44174403583536487, 0.43736112533430715, 0.41984793239700563, 0.4191768783893438, 0.4131921350520334, 0.4131222181592277, 0.41294847839862986, 0.41263948398101263, 0.4087915464851175, 0.40711590972247264, 0.40707739829207407, 0.40532152349409595, 0.3899466260961909, 0.38811099516463277, 0.38454377029356357, 0.3838010948942613, 0.37975927571607704, 0.37404456015726867, 0.3727261521553534, 0.3712988043022119, 0.3650605207504607, 0.3609143571604602, 0.3583101755758413, 0.3524199855280913, 0.3448403567258035, 0.3355917601555818, 0.32502122430671865, 0.3247137821461437, 0.32011979991183787, 0.31860022225183454, 0.3153573683844267, 0.3146899163310555, 0.3142294999789631, 0.30168117486954255, 0.2976906340203915, 0.296567906882678, 0.2954371965144938, 0.2927269173451803, 0.2923694477502928, 0.28595027583831634, 0.2758876808613453, 0.26782834913261855, 0.2658568215246351, 0.2613402376514469, 0.25038716019517004, 0.24474643486310385, 0.24337434997434132, 0.24199381570183795, 0.24046216260700573, 0.23964757065723113, 0.23048171238516368, 0.23014383692167242, 0.2295446714540403, 0.22937330749024543, 0.22933617549778107, 0.22282725966994985, 0.21735944216696013, 0.21431179456189914, 0.2142756730305285, 0.21129781281715426, 0.2097949830828117, 0.20740645117252315, 0.2074036636424251, 0.20529448912579615, 0.1987744344314829, 0.19482434666915915, 0.19190197188055735, 0.18920577673043792, 0.1772900455224334, 0.1768028615612375, 0.17571408789775142, 0.17325650418288793, 0.1690887710504228, 0.16279659422508247, 0.16191173904537784, 0.15953364969466904, 0.1586989548663617, 0.1585003179224767, 0.15064964661871122, 0.14820083824970148, 0.13035437963142132, 0.12881656156223303, 0.12520391723725652, 0.11787504181738766, 0.11719497979218255, 0.11510062032011537, 0.11377805471326424, 0.11371656938411595, 0.11338362575940865, 0.11252745084953895, 0.111114209409962, 0.10530361845596266, 0.10268245587667586, 0.09941254508248183, 0.09721150314739724, 0.0971207149314659, 0.09213750268314425, 0.09040754412318001, 0.0902040553031918, 0.08974526405016978, 0.08471845272627489, 0.06811522553283032, 0.06724713458725011, 0.06717604289541723, 0.06623437439921183, 0.058406595175611774, 0.05671298141561462, 0.055482380568620204, 0.05404139953046979, 0.04724288566341386, 0.0467956917250823, 0.043223439611668864, 0.04142017792706706, 0.03413798584459237, 0.031601911146378635, 0.02754144990040054, 0.026628319606172617, 0.025633078554832253, 0.024852054437419124, 0.024241265008263967, 0.024212654128527134, 0.01897525606739273, 0.017955168507830795, 0.015283092350993493, 0.014785917796076192, 0.013599760385663443, 0.012563227610599567, 0.011144493549130424, 0.010702501414844332, 0.009548014967060347, 0.008039459654716911, 0.007875404105144073, 0.0001525269971675708]
  - AUC: 0.78526875
  - F1: 0.691358024691
================================

Running model 'mnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.00111140000094, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.229739956694, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.0250147424495, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 0.602554449418, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 0.798959347582, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0150321763083, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.144571515133, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.0017935514407, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 0.287307336546, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0326888519708, expected label = 0

================================
You guessed 401/600 = 66.8333333333% correct.
  - False positive rate: [0.0, 0.0, 0.005, 0.005, 0.01, 0.01, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.025, 0.025, 0.025, 0.025, 0.03, 0.03, 0.035, 0.035, 0.035, 0.035, 0.035, 0.035, 0.035, 0.04, 0.04, 0.04, 0.04, 0.04, 0.045, 0.045, 0.05, 0.05, 0.055, 0.055, 0.055, 0.06, 0.06, 0.065, 0.065, 0.07, 0.07, 0.075, 0.075, 0.075, 0.075, 0.08, 0.08, 0.085, 0.09, 0.09, 0.095, 0.095, 0.095, 0.095, 0.095, 0.1, 0.1, 0.11, 0.11, 0.125, 0.125, 0.13, 0.13, 0.14, 0.14, 0.14, 0.145, 0.145, 0.145, 0.15, 0.15, 0.155, 0.155, 0.16, 0.16, 0.165, 0.165, 0.17, 0.17, 0.175, 0.175, 0.175, 0.25, 0.255, 0.255, 0.255, 0.265, 0.28, 0.28, 0.29, 0.29, 0.29, 0.295, 0.295, 0.31, 0.31, 0.315, 0.315, 0.32, 0.32, 0.33, 0.33, 0.335, 0.335, 0.345, 0.345, 0.35, 0.36, 0.365, 0.365, 0.37, 0.37, 0.375, 0.385, 0.385, 0.39, 0.39, 0.395, 0.395, 0.415, 0.415, 0.415, 0.415, 0.42, 0.425, 0.43, 0.43, 0.44, 0.44, 0.445, 0.445, 0.45, 0.45, 0.455, 0.455, 0.465, 0.465, 0.48, 0.48, 0.49, 0.49, 0.495, 0.495, 0.5, 0.5, 0.515, 0.515, 0.52, 0.52, 0.525, 0.525, 0.535, 0.54, 0.54, 0.545, 0.545, 0.55, 0.55, 0.56, 0.56, 0.565, 0.565, 0.57, 0.57, 0.59, 0.59, 0.595, 0.595, 0.6, 0.6, 0.615, 0.615, 0.625, 0.625, 0.645, 0.645, 0.65, 0.65, 0.655, 0.655, 0.66, 0.66, 0.68, 0.68, 0.685, 0.685, 0.695, 0.695, 0.72, 0.72, 0.725, 0.725, 0.735, 0.735, 0.74, 0.74, 0.745, 0.745, 0.78, 0.78, 0.79, 0.79, 0.805, 0.805, 0.815, 0.825, 0.835, 0.835, 0.87, 0.875, 0.875, 0.885, 0.9, 0.9, 0.905, 0.905, 0.91, 0.91, 0.92, 0.92, 0.925, 0.925, 1.0]
  - True positive rate: [0.0025, 0.0425, 0.0425, 0.07, 0.07, 0.08, 0.0875, 0.1275, 0.145, 0.1625, 0.1675, 0.1775, 0.1925, 0.1925, 0.1975, 0.2025, 0.2225, 0.2275, 0.2325, 0.2325, 0.2475, 0.255, 0.27, 0.27, 0.2775, 0.2775, 0.2825, 0.2925, 0.295, 0.3, 0.305, 0.3125, 0.3125, 0.315, 0.3225, 0.3325, 0.3375, 0.3375, 0.34, 0.34, 0.345, 0.345, 0.35, 0.3575, 0.36, 0.3675, 0.3675, 0.37, 0.3725, 0.385, 0.4, 0.4125, 0.4275, 0.45, 0.45, 0.455, 0.455, 0.4575, 0.4625, 0.4625, 0.47, 0.4775, 0.4825, 0.49, 0.49, 0.495, 0.5075, 0.51, 0.51, 0.535, 0.535, 0.5375, 0.5375, 0.5625, 0.5675, 0.5675, 0.57, 0.575, 0.575, 0.5775, 0.5775, 0.5825, 0.5825, 0.5925, 0.5925, 0.595, 0.595, 0.6, 0.6, 0.6025, 0.6075, 0.685, 0.685, 0.69, 0.695, 0.695, 0.695, 0.7, 0.7, 0.7025, 0.7075, 0.7075, 0.71, 0.715, 0.7175, 0.7175, 0.7225, 0.7225, 0.73, 0.73, 0.7325, 0.7325, 0.7375, 0.7375, 0.74, 0.74, 0.74, 0.74, 0.7425, 0.7425, 0.7475, 0.7525, 0.7525, 0.7575, 0.76, 0.765, 0.765, 0.7725, 0.7725, 0.775, 0.7875, 0.79, 0.7925, 0.7925, 0.8, 0.805, 0.805, 0.8075, 0.8075, 0.8125, 0.8125, 0.815, 0.815, 0.825, 0.825, 0.8275, 0.8275, 0.83, 0.83, 0.8325, 0.8325, 0.835, 0.835, 0.8375, 0.85, 0.8525, 0.8525, 0.855, 0.855, 0.8675, 0.8725, 0.8725, 0.875, 0.875, 0.885, 0.885, 0.8875, 0.8875, 0.895, 0.895, 0.9, 0.9, 0.9025, 0.9025, 0.9075, 0.9075, 0.91, 0.91, 0.915, 0.915, 0.9175, 0.9175, 0.9225, 0.9225, 0.925, 0.925, 0.9275, 0.9275, 0.93, 0.93, 0.9375, 0.9375, 0.94, 0.94, 0.9425, 0.9425, 0.945, 0.945, 0.9475, 0.9475, 0.95, 0.95, 0.9525, 0.9525, 0.955, 0.955, 0.9575, 0.9575, 0.9625, 0.9625, 0.965, 0.965, 0.9675, 0.9675, 0.975, 0.975, 0.98, 0.98, 0.9825, 0.985, 0.985, 0.985, 0.9875, 0.9875, 0.99, 0.99, 0.995, 0.995, 0.9975, 0.9975, 1.0, 1.0]
  - Thresholds: [0.9999282759560547, 0.9850969950166302, 0.9844817292577128, 0.9722007871409464, 0.9706056560447797, 0.9673457899470551, 0.9672432104791693, 0.9382017130188488, 0.9330348296116319, 0.9209671236681295, 0.9209288548565535, 0.9136529363401007, 0.9121230414126505, 0.9052228083786346, 0.9003227036635394, 0.899476125219653, 0.8830056221296894, 0.8824156925584095, 0.8810489410540965, 0.879059730557844, 0.8584425904089056, 0.8564302801021119, 0.8470650348457321, 0.8405784823390097, 0.8386562558887454, 0.8326222938974494, 0.83155889023596, 0.8311192231774639, 0.8295338525156035, 0.82551322226711, 0.8243121027693571, 0.8232135689672863, 0.819487454337755, 0.8185337248374838, 0.8155047201586433, 0.806894848776447, 0.8054890265905075, 0.8027810999468027, 0.7994796653690525, 0.7989593475815701, 0.7837118057047723, 0.7816190603906843, 0.780641921494025, 0.7638854764624824, 0.7579723858451448, 0.7487808819090871, 0.7328105521193355, 0.7313567095794398, 0.7285828573968305, 0.7106028311995414, 0.7099355655295667, 0.691919770847556, 0.6910692492048134, 0.6586456847105614, 0.6542708133008068, 0.6385030183550313, 0.6379349444222648, 0.632522250887614, 0.6219044522804286, 0.6186247103064286, 0.6131387297005448, 0.611956564250121, 0.6095672856255269, 0.6082904228249275, 0.6025544494175139, 0.5992200053763486, 0.5986054358423801, 0.5912429688190979, 0.5756751368989873, 0.5564071438261369, 0.5524385600094648, 0.5522775784649874, 0.5440143364715108, 0.5188124675727337, 0.5177809276010057, 0.5086657917249298, 0.5080210362534638, 0.500540210735349, 0.49722893262991374, 0.49655547750360224, 0.49034718239390224, 0.48618311898666855, 0.4854196621619477, 0.47715859875951516, 0.4763919891465477, 0.4740055171660018, 0.47223662604787847, 0.472236626047878, 0.46800967867368914, 0.46465680562647865, 0.45913843945764654, 0.45833333333333326, 0.44369762650162925, 0.4408770997281627, 0.4370814376801599, 0.4357296841152579, 0.42871951122821295, 0.42181885660374246, 0.41437266172963355, 0.4091879504098151, 0.40676256035777697, 0.4047954415504583, 0.40429177707543656, 0.40158869174847944, 0.3987910153655824, 0.3920346170355589, 0.3758344879228153, 0.37393324780308806, 0.3736398991409888, 0.371617203520415, 0.3674392134125369, 0.36668008772491706, 0.36252418818409193, 0.3572816906299194, 0.35183671124999005, 0.3504327178876889, 0.3493282047457194, 0.3403597437824683, 0.3383213952642432, 0.33638721383241643, 0.3241584728286852, 0.32116375836767214, 0.31867595478665905, 0.31542828993436245, 0.3138166182457865, 0.30910325126217986, 0.30830179539353125, 0.30271760158814953, 0.2856117919239158, 0.2845305935151704, 0.280077550868731, 0.2783909293189209, 0.2771854920527559, 0.2758032093930385, 0.27515603517344384, 0.2731994798496125, 0.2671340635304187, 0.26678492498776274, 0.26544359370718557, 0.2593331347045749, 0.2588657351823562, 0.2573963409203858, 0.25617141252029685, 0.2512423990466957, 0.24672545567946336, 0.2383461890479186, 0.23321216438288395, 0.23289327201149995, 0.2297399566944858, 0.22197473866879347, 0.2213000534641026, 0.21869839430133564, 0.21625560782399467, 0.21169568136486044, 0.2116278994710189, 0.21070896563778438, 0.2087319857544655, 0.20813311638101978, 0.2080203884500506, 0.19953952096922506, 0.19907244644981248, 0.1961629590627879, 0.1887185595686869, 0.18863250682797286, 0.1787741391292176, 0.17420947254340557, 0.16960763753207028, 0.16567687156673916, 0.16182126431162866, 0.16062378461509164, 0.15621052395087343, 0.14942447203980996, 0.149127512344887, 0.14130641564811108, 0.1381935420331342, 0.1339073559346691, 0.12935568046283996, 0.1270737135719381, 0.12670380360285666, 0.11868604989968629, 0.11801699798622353, 0.1101070781393561, 0.1087865180676406, 0.10695152980769919, 0.10690083537669345, 0.10679835065748407, 0.10669911718450133, 0.10624712059639267, 0.10412878957151041, 0.09752612891522308, 0.09613902841419361, 0.09157708526945249, 0.08825280664266383, 0.08721565370722222, 0.08139846987691425, 0.07869978394528716, 0.07836416664657007, 0.07016566545976767, 0.06980669348179826, 0.0690043511621525, 0.06807878656305881, 0.06294203623318041, 0.059207598154730354, 0.056294460956776614, 0.05586944872196981, 0.05423631764574017, 0.05349945595509767, 0.0452127349284318, 0.0433321449220756, 0.038971833465937064, 0.037544355866991404, 0.0351150812230273, 0.034888957345071504, 0.032688851970814094, 0.03207726604303581, 0.030576228626853656, 0.026351013184068166, 0.01896859440487585, 0.017220814824345322, 0.01699564690554085, 0.016376358490081625, 0.015032176308250654, 0.013527802859929241, 0.013484141028608315, 0.013244676741635885, 0.011468170674159148, 0.009915791291464936, 0.009135882004872949, 0.009022488911966407, 0.007733103028790851, 0.007471856030457412, 2.1495417877703853e-06]
  - AUC: 0.785
  - F1: 0.698027314112
================================

Running model 'dt' on train data 'default.txt4.train' and test data 'default.txt4.test'
Best hyperparameters were: {'max_features': 0.5, 'min_samples_leaf': 1}
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.370967741935, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 0.5, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0, expected label = 0

================================
You guessed 381/600 = 63.5% correct.
  - False positive rate: [0.0, 0.31, 0.31, 0.31, 0.315, 0.355, 0.365, 0.375, 0.375, 0.415, 0.515, 0.54, 0.545, 0.6, 0.615, 0.62, 1.0]
  - True positive rate: [0.0, 0.4825, 0.5425, 0.5725, 0.575, 0.6325, 0.6325, 0.645, 0.6475, 0.66, 0.7575, 0.7725, 0.78, 0.815, 0.815, 0.8175, 1.0]
  - Thresholds: [2.0, 1.0, 0.9696969696969697, 0.8333333333333334, 0.8, 0.7857142857142857, 0.7619047619047619, 0.6666666666666666, 0.5714285714285714, 0.5, 0.3709677419354839, 0.3333333333333333, 0.25, 0.2, 0.14285714285714285, 0.125, 0.0]
  - AUC: 0.64004375
  - F1: 0.706827309237
================================

Running model 'rf' on train data 'default.txt4.train' and test data 'default.txt4.test'
Best hyperparameters were: {'n_estimators': 10}
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.495086080029, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.373987056768, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.0436045623526, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 0.373987056768, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 0.397926558127, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.11108287885, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.13613943363, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 0.388365933278, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0535886200402, expected label = 0

================================
You guessed 348/600 = 58.0% correct.
  - False positive rate: [0.0, 0.0, 0.0, 0.005, 0.005, 0.005, 0.01, 0.01, 0.01, 0.015, 0.015, 0.04, 0.04, 0.045, 0.045, 0.05, 0.05, 0.055, 0.055, 0.07, 0.115, 0.115, 0.12, 0.125, 0.135, 0.15, 0.15, 0.16, 0.165, 0.165, 0.17, 0.17, 0.18, 0.18, 0.185, 0.185, 0.19, 0.195, 0.2, 0.2, 0.2, 0.2, 0.205, 0.205, 0.21, 0.21, 0.23, 0.23, 0.235, 0.235, 0.24, 0.25, 0.25, 0.255, 0.265, 0.265, 0.27, 0.525, 0.525, 0.53, 0.565, 0.57, 0.575, 0.575, 0.585, 0.585, 0.595, 0.595, 0.605, 0.605, 0.605, 0.61, 0.61, 0.615, 0.615, 0.62, 0.625, 0.63, 0.63, 0.635, 0.65, 0.665, 0.675, 0.675, 0.71, 0.73, 0.735, 0.735, 0.74, 0.74, 0.745, 0.745, 0.75, 0.75, 0.755, 0.765, 0.765, 0.775, 0.78, 0.78, 0.785, 0.79, 0.79, 0.84, 0.84, 0.845, 0.855, 0.855, 0.86, 0.865, 0.865, 0.87, 0.87, 0.875, 0.885, 0.89, 0.9, 0.905, 0.905, 0.915, 0.925, 0.945, 0.945, 0.96, 0.97, 0.98, 1.0]
  - True positive rate: [0.0025, 0.0175, 0.0225, 0.0775, 0.0825, 0.085, 0.11, 0.225, 0.235, 0.235, 0.2375, 0.275, 0.2775, 0.28, 0.29, 0.29, 0.295, 0.295, 0.3025, 0.3025, 0.43, 0.4325, 0.4375, 0.4375, 0.4425, 0.4425, 0.445, 0.445, 0.4475, 0.45, 0.4525, 0.455, 0.455, 0.4575, 0.4575, 0.46, 0.465, 0.4675, 0.4675, 0.4775, 0.4825, 0.4875, 0.4875, 0.5025, 0.5025, 0.5075, 0.5075, 0.51, 0.515, 0.5175, 0.5175, 0.5175, 0.5225, 0.5225, 0.525, 0.5275, 0.5275, 0.76, 0.765, 0.765, 0.7875, 0.7925, 0.7925, 0.7975, 0.7975, 0.8025, 0.8025, 0.8075, 0.8075, 0.8125, 0.8175, 0.8175, 0.82, 0.82, 0.8225, 0.8225, 0.825, 0.825, 0.8275, 0.8275, 0.83, 0.84, 0.8425, 0.845, 0.87, 0.875, 0.875, 0.88, 0.88, 0.8825, 0.8825, 0.8875, 0.8875, 0.89, 0.895, 0.895, 0.9, 0.9, 0.905, 0.9075, 0.9075, 0.91, 0.915, 0.94, 0.9475, 0.955, 0.955, 0.9625, 0.965, 0.965, 0.9675, 0.9675, 0.9725, 0.9725, 0.975, 0.9775, 0.98, 0.98, 0.985, 0.985, 0.985, 0.985, 0.99, 1.0, 1.0, 1.0, 1.0]
  - Thresholds: [0.97675526988027, 0.97655976645896, 0.9529411764705882, 0.9524141193142173, 0.9426688430635801, 0.9404451104451106, 0.940313549832027, 0.9348920515749739, 0.9181818181818182, 0.9, 0.8842432202982511, 0.8574481892423504, 0.8398412568160929, 0.8278945981554676, 0.7732220330068691, 0.7652328781002727, 0.7624566507215675, 0.7599045765589232, 0.7286582027755975, 0.6777990099833999, 0.6760624564722925, 0.663221599904784, 0.6554308239234448, 0.6493485765280305, 0.6399390485382482, 0.637465563377539, 0.6329610588730346, 0.5937721964485683, 0.562201669665608, 0.5482989616735747, 0.5457085240466119, 0.5437111879634566, 0.5329307898123687, 0.5259374035689824, 0.525935369937779, 0.5218985616137424, 0.5160326416642206, 0.4986195158331334, 0.495086080028869, 0.463951840745717, 0.4486920744273686, 0.448111653862759, 0.4412140722134799, 0.43670920676494485, 0.434076611155496, 0.40993865074873936, 0.40059788151007963, 0.40004132095329653, 0.3979265581266678, 0.3972483782885944, 0.39319181627270605, 0.39316465336476303, 0.39046710684247754, 0.38836593327838437, 0.3846267513473557, 0.3806644230096242, 0.3782167551664119, 0.3739870567678116, 0.3703200678928792, 0.3585588891052075, 0.3568854421200182, 0.3562519595528072, 0.3560787026530984, 0.35447368421052633, 0.3526884628885726, 0.3513486692828537, 0.3467419398631054, 0.34108151472224696, 0.3319547167779268, 0.3233130175779098, 0.31491773889465785, 0.3079723119817358, 0.30660588981027004, 0.29782189228799133, 0.2959441251043877, 0.28766423428564125, 0.2862109741708222, 0.28357643165732144, 0.2809996504068669, 0.26403954647527134, 0.2639948833237373, 0.2591446454860123, 0.2586433923531802, 0.2579570156498823, 0.24393824689809493, 0.23761783436333256, 0.23633142543076785, 0.23043083949377635, 0.23011783436333255, 0.22992958636094424, 0.22846651367873777, 0.2269674139025673, 0.22670791207555915, 0.22003416987794347, 0.21684736658289058, 0.2085662116302494, 0.20518862014248898, 0.20340598849408922, 0.1979908955827207, 0.19495153139326368, 0.19002868166601167, 0.1898791511108301, 0.18362915111083009, 0.17825689126927713, 0.17308916940134453, 0.1719515313932637, 0.16972486633144404, 0.16636696395878908, 0.16554545998414621, 0.1606905960582431, 0.15662214638590063, 0.1500705790123113, 0.14264656223437933, 0.13613943363048392, 0.12953898325026894, 0.12193824249067216, 0.11435495621173371, 0.11108287884992382, 0.101673224825687, 0.07222222222222222, 0.053588620040232945, 0.04360456235256127, 0.03948621357191441, 0.035138387484957886, 0.0125, 0.004, 0.0]
  - AUC: 0.6976625
  - F1: 0.596153846154
================================

