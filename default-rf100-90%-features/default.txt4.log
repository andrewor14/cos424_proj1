preprocessSentences.py:68: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  return [clean_word(w) for w in tokens if w.lower() not in stop_words and w.isalpha()]
Path: .
Training data: ./default.txt4.train
Done building things up man. Num documents in train set: 2400.
Number of features before any feature selection: 11200
Number of features after filtering out words by count threshold: 489
Done doing the feature selection thing man. Num vocabs: 440.
Output files: ./out*
Runtime: 4.32151913643
Running model 'mybnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
Num train examples = 2400, positive prior = 0.458333333333, negative prior = 0.541666666667
Using 440 features: dialogu, unit, music, relat, hold, want, beauti, fit, wast, came...
411 features are used in positive reviews: forget, lack, abil, go, follow, tv, friendli, send, certainli, worth...
415 features are used in negative reviews: forget, lack, poorli, abil, go, follow, hate, tv, friendli, send...
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  positive probability = 1.03373420058e-67, negative probability = 1.89266974526e-66
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  positive probability = 0.000831820931639, negative probability = 0.00249615975422
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  positive probability = 2.13647644583e-19, negative probability = 2.49844715642e-18
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  positive probability = 2.90419938918e-44, negative probability = 3.07131100874e-45
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  positive probability = 4.73786577185e-14, negative probability = 5.79078153316e-15
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  positive probability = 1.02744341871e-09, negative probability = 4.41745020816e-08
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  positive probability = 9.39418491438e-37, negative probability = 7.68668536417e-37
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  positive probability = 1.07362731606e-64, negative probability = 1.64721586706e-63
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  positive probability = 3.48674642124e-30, negative probability = 1.70049091905e-30
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  positive probability = 2.36311986304e-08, negative probability = 4.74139655676e-07
  predicted label = 0, expected label = 0

================================
You guessed 434/600 = 72.3333333333% correct.
  - False positive rate: [0.0, 0.49, 1.0]
  - True positive rate: [0.0, 0.83, 1.0]
  - Thresholds: [2, 1, 0]
  - AUC: 0.67
  - Precision: 0.772093023256
  - Recall: 0.83
  - F1: 0.8
================================

Running model 'mymnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
Num train examples = 2400, positive prior = 0.458333333333, negative prior = 0.541666666667
Using 440 features: dialogu, unit, music, relat, hold, want, beauti, fit, wast, came...
411 features are used in positive reviews: forget, lack, abil, go, follow, tv, friendli, send, certainli, worth...
415 features are used in negative reviews: forget, lack, poorli, abil, go, follow, hate, tv, friendli, send...
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  positive probability = 2.56977099451e-71, negative probability = 1.90782603324e-69
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  positive probability = 0.000595238095238, negative probability = 0.00186781609195
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  positive probability = 2.05269405699e-20, negative probability = 4.02475832147e-19
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  positive probability = 3.17382622737e-46, negative probability = 3.9650606587e-47
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  positive probability = 8.88970032493e-15, negative probability = 1.35845688897e-15
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  positive probability = 3.76478808761e-10, negative probability = 1.91248179583e-08
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  positive probability = 1.21185445122e-38, negative probability = 1.83343251386e-38
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  positive probability = 4.87588716925e-68, negative probability = 2.70609994877e-66
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  positive probability = 9.79194695146e-32, negative probability = 7.49763135564e-32
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  positive probability = 8.6590126015e-09, negative probability = 1.98651334922e-07
  predicted label = 0, expected label = 0

================================
You guessed 427/600 = 71.1666666667% correct.
  - False positive rate: [0.0, 0.41, 1.0]
  - True positive rate: [0.0, 0.7725, 1.0]
  - Thresholds: [2, 1, 0]
  - AUC: 0.68125
  - Precision: 0.790281329923
  - Recall: 0.7725
  - F1: 0.781289506953
================================

Running model 'bnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.209794983083, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.18920577673, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.0283981000416, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 0.36091435716, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 0.779205511592, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0133127583282, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.158500317922, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.0107025014148, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 0.27600947641, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0275414499004, expected label = 0

================================
You guessed 400/600 = 66.6666666667% correct.
  - False positive rate: [0.0, 0.0, 0.005, 0.005, 0.01, 0.01, 0.015, 0.015, 0.015, 0.015, 0.02, 0.02, 0.02, 0.02, 0.02, 0.025, 0.025, 0.025, 0.03, 0.03, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.045, 0.045, 0.045, 0.05, 0.05, 0.05, 0.05, 0.055, 0.055, 0.06, 0.06, 0.065, 0.065, 0.07, 0.07, 0.075, 0.075, 0.075, 0.08, 0.08, 0.085, 0.085, 0.095, 0.095, 0.1, 0.1, 0.105, 0.105, 0.105, 0.105, 0.115, 0.115, 0.115, 0.115, 0.12, 0.12, 0.125, 0.125, 0.13, 0.14, 0.145, 0.145, 0.15, 0.15, 0.15, 0.16, 0.16, 0.165, 0.165, 0.17, 0.17, 0.175, 0.175, 0.185, 0.185, 0.185, 0.19, 0.19, 0.195, 0.195, 0.2, 0.2, 0.205, 0.205, 0.205, 0.205, 0.21, 0.21, 0.215, 0.215, 0.215, 0.22, 0.22, 0.295, 0.3, 0.3, 0.305, 0.305, 0.315, 0.315, 0.335, 0.35, 0.355, 0.355, 0.355, 0.37, 0.37, 0.375, 0.375, 0.38, 0.38, 0.39, 0.39, 0.395, 0.395, 0.415, 0.415, 0.42, 0.425, 0.425, 0.435, 0.435, 0.445, 0.445, 0.455, 0.455, 0.46, 0.46, 0.465, 0.47, 0.47, 0.49, 0.495, 0.5, 0.5, 0.505, 0.505, 0.51, 0.51, 0.52, 0.52, 0.53, 0.54, 0.54, 0.545, 0.55, 0.56, 0.565, 0.565, 0.575, 0.585, 0.585, 0.59, 0.59, 0.595, 0.595, 0.605, 0.605, 0.62, 0.62, 0.63, 0.63, 0.635, 0.635, 0.64, 0.64, 0.66, 0.66, 0.685, 0.685, 0.69, 0.69, 0.7, 0.7, 0.705, 0.705, 0.73, 0.73, 0.735, 0.735, 0.75, 0.75, 0.755, 0.755, 0.775, 0.775, 0.79, 0.79, 0.815, 0.815, 0.845, 0.845, 0.85, 0.86, 0.865, 0.865, 0.895, 0.895, 0.905, 0.91, 0.92, 0.94, 0.94, 0.945, 0.945, 0.965, 0.965, 1.0]
  - True positive rate: [0.0025, 0.06, 0.06, 0.0875, 0.095, 0.125, 0.125, 0.145, 0.165, 0.17, 0.17, 0.175, 0.195, 0.21, 0.215, 0.215, 0.2325, 0.2375, 0.2375, 0.2725, 0.2725, 0.275, 0.2825, 0.2925, 0.3, 0.3175, 0.3325, 0.335, 0.335, 0.3375, 0.3425, 0.3425, 0.355, 0.36, 0.375, 0.375, 0.385, 0.385, 0.3875, 0.39, 0.3975, 0.4, 0.41, 0.425, 0.4325, 0.445, 0.4475, 0.45, 0.45, 0.4525, 0.4525, 0.46, 0.46, 0.465, 0.465, 0.4975, 0.505, 0.515, 0.515, 0.52, 0.53, 0.535, 0.535, 0.5625, 0.5625, 0.565, 0.565, 0.5675, 0.5675, 0.5775, 0.5775, 0.58, 0.585, 0.585, 0.5875, 0.5875, 0.59, 0.59, 0.595, 0.595, 0.6, 0.6, 0.6025, 0.6075, 0.6075, 0.6125, 0.6125, 0.615, 0.615, 0.6175, 0.6175, 0.62, 0.625, 0.6325, 0.6325, 0.6375, 0.6375, 0.6425, 0.645, 0.645, 0.65, 0.7275, 0.7275, 0.73, 0.73, 0.735, 0.735, 0.74, 0.74, 0.74, 0.74, 0.745, 0.7525, 0.7525, 0.755, 0.755, 0.76, 0.7625, 0.765, 0.765, 0.77, 0.77, 0.7725, 0.7725, 0.775, 0.775, 0.7775, 0.79, 0.79, 0.795, 0.795, 0.8075, 0.8075, 0.82, 0.82, 0.8225, 0.825, 0.825, 0.83, 0.83, 0.8375, 0.8375, 0.8425, 0.8425, 0.8475, 0.8475, 0.85, 0.85, 0.86, 0.86, 0.86, 0.8725, 0.885, 0.885, 0.885, 0.885, 0.89, 0.895, 0.895, 0.8975, 0.8975, 0.905, 0.905, 0.915, 0.915, 0.92, 0.92, 0.9225, 0.9225, 0.925, 0.925, 0.9275, 0.9275, 0.93, 0.93, 0.9375, 0.9375, 0.94, 0.94, 0.9425, 0.9425, 0.945, 0.945, 0.9475, 0.9475, 0.95, 0.95, 0.9525, 0.9525, 0.955, 0.955, 0.9575, 0.9575, 0.96, 0.96, 0.9675, 0.9675, 0.97, 0.97, 0.9725, 0.9725, 0.98, 0.98, 0.9825, 0.9825, 0.985, 0.985, 0.9875, 0.9875, 0.9875, 0.9925, 0.9925, 0.9975, 0.9975, 1.0, 1.0]
  - Thresholds: [0.9992695786156071, 0.9754936294830339, 0.9752252702133777, 0.9601575565625721, 0.9597814742380121, 0.9373418794547304, 0.9365174467846185, 0.922738662783533, 0.9220047675225429, 0.9153919975477415, 0.9127680728253152, 0.9109917451106776, 0.8941902650730107, 0.893700596747835, 0.8905674420908352, 0.8856480504937608, 0.8768948497386586, 0.8762261581240217, 0.875594649058373, 0.8383403121953407, 0.8320529705967746, 0.8277807842956412, 0.8248343448109161, 0.8143638295397339, 0.8103493183257017, 0.7970685485138453, 0.7942150023476692, 0.7928657770252937, 0.7919558337912703, 0.7865053164781117, 0.7827521836952113, 0.779205511591813, 0.7620052591567663, 0.7559602783381719, 0.7338619993126997, 0.7323235457213881, 0.7162101694496406, 0.7150099690905584, 0.7133684494968416, 0.7127355446139034, 0.686198860968413, 0.6789106584721574, 0.6635110656392476, 0.6551061526632395, 0.638432046384343, 0.637732628708513, 0.6342930209106372, 0.63076787117421, 0.629909666572907, 0.6292045210717538, 0.62190862721069, 0.6096292877858052, 0.6033392313326037, 0.5998702121295214, 0.5943931212222674, 0.5745769136404167, 0.5735593489566474, 0.5609329038847336, 0.5518841595008409, 0.5410428270536443, 0.5397414792223578, 0.5365232463220612, 0.5282688812060367, 0.4996048676476411, 0.49214014491514607, 0.4891181368929267, 0.48415149478243263, 0.48381746302707995, 0.4725310855140571, 0.4606491596971448, 0.45921570402039463, 0.4582181929511165, 0.4580478733236439, 0.4566115159461931, 0.4535434238789751, 0.45228866804655576, 0.45212896066354685, 0.4516910017376092, 0.4464991938271418, 0.4438235169789934, 0.44331464606688487, 0.4432677974484726, 0.4417763359135687, 0.44174403583536487, 0.43736112533430715, 0.41984793239700563, 0.4191768783893438, 0.4131921350520334, 0.4131222181592277, 0.41294847839862986, 0.41263948398101263, 0.4087915464851175, 0.40711590972247264, 0.40707739829207407, 0.40532152349409595, 0.3899466260961909, 0.38811099516463277, 0.38454377029356357, 0.3838010948942613, 0.37975927571607704, 0.37404456015726867, 0.3727261521553534, 0.3712988043022119, 0.3650605207504607, 0.3609143571604602, 0.3583101755758413, 0.3524199855280913, 0.3448403567258035, 0.3355917601555818, 0.32502122430671865, 0.3247137821461437, 0.32011979991183787, 0.31860022225183454, 0.3153573683844267, 0.3146899163310566, 0.3142294999789631, 0.30168117486954255, 0.2976906340203915, 0.296567906882678, 0.2954371965144938, 0.2927269173451803, 0.29236944775029383, 0.28595027583831634, 0.2758876808613453, 0.26782834913261855, 0.2658568215246351, 0.2613402376514469, 0.25038716019517004, 0.24474643486310385, 0.24337434997434046, 0.24199381570183795, 0.24046216260700573, 0.23964757065723113, 0.23048171238516368, 0.23014383692167162, 0.2295446714540403, 0.22937330749024543, 0.22933617549778107, 0.22282725966994985, 0.21735944216696168, 0.21431179456189914, 0.21427567303052925, 0.21129781281715426, 0.2097949830828117, 0.20740645117252315, 0.2074036636424251, 0.20529448912579615, 0.1987744344314829, 0.19482434666915846, 0.19190197188055735, 0.18920577673043792, 0.1772900455224334, 0.1768028615612375, 0.17571408789775142, 0.17325650418288793, 0.16908877105042222, 0.16279659422508247, 0.16191173904537784, 0.15953364969466904, 0.15869895486636282, 0.1585003179224767, 0.15064964661871122, 0.14820083824970148, 0.13035437963142132, 0.12881656156223303, 0.12520391723725652, 0.11787504181738766, 0.11719497979218255, 0.11510062032011537, 0.11377805471326424, 0.11371656938411553, 0.11338362575940865, 0.11252745084953895, 0.111114209409962, 0.10530361845596266, 0.10268245587667586, 0.09941254508248183, 0.09721150314739724, 0.0971207149314659, 0.09213750268314425, 0.09040754412318001, 0.0902040553031918, 0.08974526405016978, 0.08471845272627519, 0.06811522553283032, 0.06724713458725011, 0.06717604289541723, 0.06623437439921206, 0.058406595175611774, 0.05671298141561462, 0.055482380568620204, 0.05404139953046979, 0.04724288566341386, 0.0467956917250823, 0.043223439611669016, 0.04142017792706706, 0.03413798584459225, 0.031601911146378635, 0.02754144990040054, 0.026628319606172617, 0.025633078554832527, 0.024852054437419124, 0.02424126500826405, 0.024212654128527134, 0.01897525606739273, 0.017955168507830858, 0.015283092350993602, 0.014785917796076192, 0.013599760385663443, 0.012563227610599657, 0.011144493549130463, 0.010702501414844332, 0.009548014967060347, 0.008039459654716911, 0.007875404105144045, 0.0001525269971675708]
  - AUC: 0.78526875
  - Precision: 0.903225806452
  - Recall: 0.56
  - F1: 0.691358024691
================================

Running model 'mnb' on train data 'default.txt4.train' and test data 'default.txt4.test'
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.00111140000094, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.229739956694, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.0250147424495, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 0.602554449418, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 0.798959347582, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0150321763083, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.144571515133, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.0017935514407, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 0.287307336546, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0326888519708, expected label = 0

================================
You guessed 401/600 = 66.8333333333% correct.
  - False positive rate: [0.0, 0.0, 0.005, 0.005, 0.01, 0.01, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.025, 0.025, 0.025, 0.025, 0.03, 0.03, 0.035, 0.035, 0.035, 0.035, 0.035, 0.035, 0.035, 0.04, 0.04, 0.04, 0.04, 0.04, 0.045, 0.045, 0.05, 0.05, 0.055, 0.055, 0.055, 0.06, 0.06, 0.065, 0.065, 0.07, 0.07, 0.075, 0.075, 0.075, 0.075, 0.08, 0.08, 0.085, 0.09, 0.09, 0.095, 0.095, 0.095, 0.095, 0.095, 0.1, 0.1, 0.11, 0.11, 0.125, 0.125, 0.13, 0.13, 0.14, 0.14, 0.14, 0.145, 0.145, 0.145, 0.15, 0.15, 0.155, 0.155, 0.16, 0.16, 0.165, 0.165, 0.17, 0.17, 0.175, 0.175, 0.175, 0.25, 0.255, 0.255, 0.255, 0.265, 0.28, 0.28, 0.29, 0.29, 0.29, 0.295, 0.295, 0.31, 0.31, 0.315, 0.315, 0.32, 0.32, 0.33, 0.33, 0.335, 0.335, 0.345, 0.345, 0.35, 0.36, 0.365, 0.365, 0.37, 0.37, 0.375, 0.385, 0.385, 0.39, 0.39, 0.395, 0.395, 0.415, 0.415, 0.415, 0.415, 0.42, 0.425, 0.43, 0.43, 0.44, 0.44, 0.445, 0.445, 0.45, 0.45, 0.455, 0.455, 0.465, 0.465, 0.48, 0.48, 0.49, 0.49, 0.495, 0.495, 0.5, 0.5, 0.515, 0.515, 0.52, 0.52, 0.525, 0.525, 0.535, 0.54, 0.54, 0.545, 0.545, 0.55, 0.55, 0.56, 0.56, 0.565, 0.565, 0.57, 0.57, 0.59, 0.59, 0.595, 0.595, 0.6, 0.6, 0.615, 0.615, 0.625, 0.625, 0.645, 0.645, 0.65, 0.65, 0.655, 0.655, 0.66, 0.66, 0.68, 0.68, 0.685, 0.685, 0.695, 0.695, 0.72, 0.72, 0.725, 0.725, 0.735, 0.735, 0.74, 0.74, 0.745, 0.745, 0.78, 0.78, 0.79, 0.79, 0.805, 0.805, 0.815, 0.825, 0.835, 0.835, 0.87, 0.875, 0.875, 0.885, 0.9, 0.9, 0.905, 0.905, 0.91, 0.91, 0.92, 0.92, 0.925, 0.925, 0.94, 0.95, 1.0]
  - True positive rate: [0.0025, 0.0425, 0.0425, 0.07, 0.07, 0.08, 0.0875, 0.1275, 0.145, 0.1625, 0.1675, 0.1775, 0.1925, 0.1925, 0.1975, 0.2025, 0.2225, 0.2275, 0.2325, 0.2325, 0.2475, 0.255, 0.27, 0.27, 0.2775, 0.2775, 0.2825, 0.2925, 0.295, 0.3, 0.305, 0.3125, 0.3125, 0.315, 0.3225, 0.3325, 0.3375, 0.3375, 0.34, 0.34, 0.345, 0.345, 0.35, 0.3575, 0.36, 0.3675, 0.3675, 0.37, 0.3725, 0.385, 0.4, 0.4125, 0.4275, 0.45, 0.45, 0.455, 0.455, 0.4575, 0.4625, 0.4625, 0.47, 0.4775, 0.4825, 0.49, 0.49, 0.495, 0.5075, 0.51, 0.51, 0.535, 0.535, 0.5375, 0.5375, 0.5625, 0.5675, 0.5675, 0.57, 0.575, 0.575, 0.5775, 0.5775, 0.5825, 0.5825, 0.5925, 0.5925, 0.595, 0.595, 0.6, 0.6, 0.6025, 0.6075, 0.685, 0.685, 0.69, 0.695, 0.695, 0.695, 0.7, 0.7, 0.7025, 0.7075, 0.7075, 0.71, 0.715, 0.7175, 0.7175, 0.7225, 0.7225, 0.73, 0.73, 0.7325, 0.7325, 0.7375, 0.7375, 0.74, 0.74, 0.74, 0.74, 0.7425, 0.7425, 0.7475, 0.7525, 0.7525, 0.7575, 0.76, 0.765, 0.765, 0.7725, 0.7725, 0.775, 0.7875, 0.79, 0.7925, 0.7925, 0.8, 0.805, 0.805, 0.8075, 0.8075, 0.8125, 0.8125, 0.815, 0.815, 0.825, 0.825, 0.8275, 0.8275, 0.83, 0.83, 0.8325, 0.8325, 0.835, 0.835, 0.8375, 0.85, 0.8525, 0.8525, 0.855, 0.855, 0.8675, 0.8725, 0.8725, 0.875, 0.875, 0.885, 0.885, 0.8875, 0.8875, 0.895, 0.895, 0.9, 0.9, 0.9025, 0.9025, 0.9075, 0.9075, 0.91, 0.91, 0.915, 0.915, 0.9175, 0.9175, 0.9225, 0.9225, 0.925, 0.925, 0.9275, 0.9275, 0.93, 0.93, 0.9375, 0.9375, 0.94, 0.94, 0.9425, 0.9425, 0.945, 0.945, 0.9475, 0.9475, 0.95, 0.95, 0.9525, 0.9525, 0.955, 0.955, 0.9575, 0.9575, 0.9625, 0.9625, 0.965, 0.965, 0.9675, 0.9675, 0.975, 0.975, 0.98, 0.98, 0.9825, 0.985, 0.985, 0.985, 0.9875, 0.9875, 0.99, 0.99, 0.995, 0.995, 0.9975, 0.9975, 1.0, 1.0, 1.0, 1.0]
  - Thresholds: [0.9999282759560547, 0.9850969950166302, 0.9844817292577128, 0.9722007871409464, 0.9706056560447762, 0.9673457899470551, 0.9672432104791693, 0.9382017130188488, 0.9330348296116319, 0.9209671236681295, 0.9209288548565535, 0.9136529363401007, 0.9121230414126505, 0.9052228083786346, 0.9003227036635394, 0.899476125219653, 0.8830056221296894, 0.8824156925584095, 0.8810489410540934, 0.879059730557844, 0.8584425904089056, 0.8564302801021119, 0.8470650348457321, 0.8405784823390097, 0.8386562558887454, 0.8326222938974494, 0.83155889023596, 0.8311192231774639, 0.8295338525156035, 0.82551322226711, 0.8243121027693571, 0.8232135689672863, 0.819487454337755, 0.8185337248374838, 0.8155047201586433, 0.806894848776447, 0.8054890265905075, 0.8027810999468027, 0.7994796653690525, 0.7989593475815701, 0.7837118057047723, 0.7816190603906843, 0.780641921494025, 0.7638854764624824, 0.7579723858451448, 0.7487808819090871, 0.7328105521193355, 0.7313567095794398, 0.7285828573968305, 0.7106028311995414, 0.7099355655295667, 0.691919770847556, 0.6910692492048134, 0.6586456847105614, 0.6542708133008068, 0.6385030183550313, 0.6379349444222648, 0.632522250887614, 0.6219044522804286, 0.6186247103064286, 0.6131387297005448, 0.611956564250121, 0.6095672856255269, 0.6082904228249275, 0.6025544494175139, 0.5992200053763486, 0.5986054358423801, 0.5912429688190979, 0.5756751368989873, 0.5564071438261369, 0.5524385600094648, 0.5522775784649874, 0.5440143364715108, 0.5188124675727337, 0.5177809276010057, 0.5086657917249298, 0.5080210362534638, 0.500540210735349, 0.49722893262991374, 0.4965554775036005, 0.49034718239390224, 0.48618311898666855, 0.4854196621619477, 0.47715859875951516, 0.4763919891465477, 0.4740055171660018, 0.47223662604787847, 0.472236626047878, 0.46800967867368914, 0.46465680562647865, 0.45913843945764654, 0.45833333333333326, 0.44369762650162925, 0.4408770997281627, 0.4370814376801599, 0.4357296841152579, 0.42871951122821295, 0.42181885660374097, 0.41437266172963355, 0.40918795040981654, 0.40676256035777697, 0.4047954415504583, 0.404291777075438, 0.40158869174847944, 0.3987910153655824, 0.3920346170355589, 0.3758344879228153, 0.37393324780308806, 0.3736398991409888, 0.371617203520415, 0.3674392134125369, 0.36668008772491706, 0.36252418818409193, 0.3572816906299194, 0.35183671124999005, 0.3504327178876902, 0.3493282047457194, 0.3403597437824683, 0.3383213952642432, 0.33638721383241643, 0.3241584728286852, 0.32116375836767214, 0.31867595478665905, 0.31542828993436245, 0.3138166182457865, 0.30910325126217986, 0.30830179539353125, 0.30271760158814953, 0.2856117919239158, 0.2845305935151704, 0.280077550868731, 0.2783909293189209, 0.2771854920527559, 0.2758032093930385, 0.27515603517344384, 0.2731994798496125, 0.26713406353041963, 0.26678492498776274, 0.26544359370718557, 0.2593331347045749, 0.2588657351823562, 0.2573963409203858, 0.25617141252029685, 0.2512423990466957, 0.24672545567946336, 0.2383461890479186, 0.23321216438288395, 0.23289327201149995, 0.2297399566944858, 0.22197473866879347, 0.221300053464101, 0.21869839430133564, 0.21625560782399542, 0.21169568136486044, 0.2116278994710189, 0.21070896563778438, 0.2087319857544655, 0.20813311638101978, 0.2080203884500506, 0.19953952096922506, 0.19907244644981248, 0.1961629590627879, 0.1887185595686869, 0.18863250682797286, 0.17877413912921697, 0.17420947254340496, 0.1696076375320715, 0.16567687156673974, 0.16182126431162866, 0.16062378461509164, 0.15621052395087343, 0.14942447203980996, 0.149127512344887, 0.14130641564811108, 0.1381935420331347, 0.1339073559346691, 0.12935568046283996, 0.1270737135719381, 0.12670380360285666, 0.11868604989968629, 0.11801699798622353, 0.1101070781393559, 0.10878651806764021, 0.10695152980769919, 0.10690083537669345, 0.10679835065748407, 0.10669911718450133, 0.10624712059639267, 0.10412878957151041, 0.09752612891522273, 0.09613902841419567, 0.09157708526945249, 0.0882528066426632, 0.0872156537072219, 0.08139846987691425, 0.07869978394528716, 0.07836416664657007, 0.07016566545976742, 0.06980669348179826, 0.0690043511621525, 0.06807878656305869, 0.06294203623318041, 0.059207598154730354, 0.056294460956776614, 0.05586944872196981, 0.05423631764574017, 0.05349945595509767, 0.0452127349284318, 0.0433321449220756, 0.038971833465937064, 0.037544355866991404, 0.0351150812230273, 0.034888957345071386, 0.032688851970814094, 0.03207726604303581, 0.030576228626853656, 0.026351013184068166, 0.01896859440487585, 0.017220814824345322, 0.01699564690554085, 0.016376358490081625, 0.015032176308250654, 0.013527802859929241, 0.01348414102860841, 0.013244676741635791, 0.011468170674159148, 0.009915791291464936, 0.009135882004872885, 0.009022488911966374, 0.007733103028790851, 0.0074718560304574385, 0.00590404734888919, 0.005254034333846684, 2.1495417877703853e-06]
  - AUC: 0.785
  - Precision: 0.888030888031
  - Recall: 0.575
  - F1: 0.698027314112
================================

Running model 'dt' on train data 'default.txt4.train' and test data 'default.txt4.test'
Best hyperparameters were: {'max_features': 0.5, 'min_samples_leaf': 1}
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.370967741935, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0, expected label = 0

================================
You guessed 384/600 = 64.0% correct.
  - False positive rate: [0.0, 0.31, 0.31, 0.31, 0.31, 0.315, 0.35, 0.36, 0.37, 0.37, 0.4, 0.495, 0.525, 0.53, 0.58, 0.6, 0.61, 1.0]
  - True positive rate: [0.0, 0.495, 0.55, 0.56, 0.575, 0.5775, 0.64, 0.6425, 0.65, 0.6525, 0.66, 0.7575, 0.7675, 0.775, 0.805, 0.805, 0.805, 1.0]
  - Thresholds: [2.0, 1.0, 0.9696969696969697, 0.8888888888888888, 0.8333333333333334, 0.8, 0.7857142857142857, 0.7619047619047619, 0.6666666666666666, 0.5714285714285714, 0.5, 0.3709677419354839, 0.3333333333333333, 0.25, 0.2, 0.14285714285714285, 0.125, 0.0]
  - AUC: 0.6431625
  - Precision: 0.767441860465
  - Recall: 0.66
  - F1: 0.709677419355
================================

Running model 'rf' on train data 'default.txt4.train' and test data 'default.txt4.test'
------------------------------------------------------------------------
Classifying line:
  1801	I am far from a sushi connoisseur but I can definitely tell the difference between good food and bad food and this was certainly bad food.	0
  words = [far, sushi, connoisseur, definit, tell, differ, good, food, bad, food, certainli, bad, food, far sushi, sushi connoisseur, connoisseur definit, definit tell, tell differ, differ good, good food, food bad, bad food, food certainli, certainli bad, bad food]
  predicted label = 0.611422218963, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1802	I was so insulted.	0
  words = [insult]
  predicted label = 0.36806860739, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1803	The last 3 times I had lunch here has been bad.	0
  words = [last, time, lunch, bad, last time, time lunch, lunch bad]
  predicted label = 0.0616599939001, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1804	The chicken wings contained the driest chicken meat I have ever eaten.	0
  words = [chicken, wing, contain, driest, chicken, meat, ever, eaten, chicken wing, wing contain, contain driest, driest chicken, chicken meat, meat ever, ever eaten]
  predicted label = 0.319016043306, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1805	Definitely not worth the $3 I paid.	0
  words = [definit, worth, paid, definit worth, worth paid]
  predicted label = 0.448500235755, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1806	The manager was the worst.	0
  words = [manag, worst, manag worst]
  predicted label = 0.00763792743953, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1807	I don't think I'll be running back to Carly's anytime soon for food.	0
  words = [think, run, back, carli, anytim, soon, food, think run, run back, back carli, carli anytim, anytim soon, soon food]
  predicted label = 0.160671085928, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1808	This is was due to the fact that it took 20 minutes to be acknowledged, then another 35 minutes to get our food...and they kept forgetting things.	0
  words = [due, fact, took, minut, acknowledg, anoth, minut, get, food, kept, forget, thing, due fact, fact took, took minut, minut acknowledg, acknowledg anoth, anoth minut, minut get, get food, food kept, kept forget, forget thing]
  predicted label = 0.131426651213, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1809	The one down note is the ventilation could use some upgrading.	0
  words = [one, note, ventil, could, use, upgrad, one note, note ventil, ventil could, could use, use upgrad]
  predicted label = 0.343136088571, expected label = 0
------------------------------------------------------------------------
Classifying line:
  1810	Don't waste your time here.	0
  words = [wast, time, wast time]
  predicted label = 0.0533164709989, expected label = 0

================================
You guessed 351/600 = 58.5% correct.
  - False positive rate: [0.0, 0.0, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.01, 0.01, 0.015, 0.015, 0.04, 0.04, 0.04, 0.04, 0.045, 0.045, 0.05, 0.05, 0.055, 0.055, 0.055, 0.1, 0.1, 0.1, 0.105, 0.105, 0.11, 0.11, 0.115, 0.115, 0.125, 0.135, 0.135, 0.15, 0.15, 0.16, 0.16, 0.165, 0.165, 0.165, 0.17, 0.17, 0.18, 0.18, 0.185, 0.185, 0.195, 0.195, 0.2, 0.2, 0.205, 0.205, 0.21, 0.215, 0.215, 0.22, 0.22, 0.22, 0.225, 0.225, 0.23, 0.23, 0.23, 0.24, 0.25, 0.255, 0.255, 0.255, 0.255, 0.26, 0.46, 0.46, 0.47, 0.47, 0.47, 0.475, 0.475, 0.49, 0.49, 0.495, 0.495, 0.5, 0.5, 0.505, 0.505, 0.51, 0.51, 0.515, 0.515, 0.52, 0.52, 0.525, 0.54, 0.545, 0.545, 0.56, 0.56, 0.565, 0.565, 0.57, 0.57, 0.605, 0.625, 0.63, 0.63, 0.645, 0.655, 0.665, 0.665, 0.68, 0.68, 0.685, 0.685, 0.695, 0.7, 0.7, 0.71, 0.725, 0.725, 0.745, 0.745, 0.75, 0.75, 0.76, 0.76, 0.765, 0.795, 0.815, 0.815, 0.82, 0.82, 0.825, 0.825, 0.83, 0.835, 0.84, 0.84, 0.845, 0.845, 0.85, 0.85, 0.855, 0.86, 0.875, 0.875, 0.88, 0.88, 0.89, 0.89, 0.905, 0.905, 0.93, 0.95, 0.95, 0.96, 0.975, 0.98, 0.98, 0.985, 1.0]
  - True positive rate: [0.015, 0.03, 0.045, 0.05, 0.155, 0.16, 0.165, 0.1725, 0.1725, 0.175, 0.2225, 0.235, 0.2625, 0.2675, 0.2725, 0.275, 0.275, 0.2775, 0.28, 0.2975, 0.2975, 0.3025, 0.3175, 0.405, 0.4075, 0.43, 0.43, 0.4325, 0.435, 0.4375, 0.4375, 0.44, 0.44, 0.44, 0.4425, 0.4425, 0.445, 0.445, 0.4475, 0.4475, 0.4525, 0.4575, 0.4575, 0.4625, 0.4625, 0.465, 0.47, 0.475, 0.475, 0.4775, 0.4775, 0.4825, 0.4825, 0.49, 0.49, 0.4925, 0.495, 0.495, 0.5075, 0.515, 0.515, 0.525, 0.525, 0.53, 0.54, 0.54, 0.5425, 0.5425, 0.545, 0.55, 0.5575, 0.5575, 0.75, 0.755, 0.7575, 0.76, 0.7675, 0.7675, 0.77, 0.77, 0.7725, 0.7725, 0.775, 0.775, 0.7775, 0.78, 0.7825, 0.785, 0.7875, 0.7875, 0.7925, 0.7925, 0.795, 0.795, 0.795, 0.795, 0.8025, 0.8025, 0.8075, 0.8075, 0.81, 0.81, 0.8125, 0.8325, 0.8325, 0.835, 0.84, 0.845, 0.85, 0.85, 0.855, 0.855, 0.8575, 0.8575, 0.8675, 0.87, 0.87, 0.875, 0.875, 0.875, 0.8775, 0.895, 0.8975, 0.8975, 0.9025, 0.9025, 0.905, 0.905, 0.9225, 0.9225, 0.93, 0.93, 0.9375, 0.9375, 0.94, 0.9425, 0.9475, 0.9475, 0.9525, 0.9575, 0.96, 0.96, 0.9625, 0.9625, 0.9675, 0.9675, 0.975, 0.975, 0.98, 0.98, 0.9825, 0.9825, 0.985, 0.985, 0.985, 0.9875, 0.9875, 0.9975, 0.9975, 1.0, 1.0, 1.0]
  - Thresholds: [0.9693103054529082, 0.9524638471378618, 0.9495199126200405, 0.9469732615873643, 0.9461675598329784, 0.9441739621698835, 0.9415053451818031, 0.9368976060287053, 0.9358811271427121, 0.9320372434680464, 0.9271572321292204, 0.8691000554914049, 0.868190964582314, 0.8622274267651178, 0.8613183358560268, 0.8608280497802325, 0.8378131845957024, 0.8263211787498382, 0.8111335711155341, 0.7360634517725961, 0.7301793949087976, 0.708028049167638, 0.7037487401221822, 0.7013042956777379, 0.6986501966930131, 0.6953915822052521, 0.6858435998835849, 0.6849927986005739, 0.6821609095164355, 0.6742120853818615, 0.6516905252314311, 0.6460378488984608, 0.6359325793367206, 0.6201292891352403, 0.6136315961951057, 0.6045579968645609, 0.5817864734129431, 0.5649980703006792, 0.5483624895709917, 0.5219196053649628, 0.514973605054917, 0.5036835204684408, 0.503138698599776, 0.5021223776553909, 0.4963399500469604, 0.4951828741918633, 0.4944133942927458, 0.4854468354563354, 0.47236136488105, 0.47088404749368096, 0.46867186789491944, 0.45079601866787017, 0.44850023575507747, 0.4338774593462224, 0.4335989667077412, 0.4239593999344892, 0.42258735586899887, 0.42240640613107255, 0.4196031661456787, 0.40851520981386585, 0.4080102603711011, 0.4058446402535828, 0.4019166446818613, 0.39815173548958044, 0.3926094432107456, 0.3890242184682417, 0.3842563231515283, 0.37861404121148157, 0.37690442499331506, 0.3742393109657052, 0.37163334293638406, 0.36890036779396174, 0.36806860739015723, 0.3666472353362595, 0.36632507840729184, 0.3655203115326718, 0.36325212423490727, 0.3610825300934111, 0.3610273986431446, 0.35893234122076706, 0.3573971900933652, 0.3570200468565504, 0.3555245140066092, 0.3514027045384795, 0.3501155602101172, 0.3491102805006201, 0.34839721626725906, 0.3465270181943309, 0.34536546544442914, 0.3444277280395601, 0.3433679065800323, 0.34313608857125105, 0.3427370110617046, 0.33987601561477854, 0.3377497658786308, 0.33224815652864015, 0.32890678555259567, 0.3190160433059773, 0.3172103749318017, 0.3168055306427687, 0.3161804853773015, 0.31561913752973775, 0.3145177073044547, 0.31205153263859614, 0.2941602282477178, 0.2923595370388041, 0.2877527397461975, 0.285831261258026, 0.2830852689256283, 0.27854124344750014, 0.2772419906472436, 0.26641554245151444, 0.2663592143409247, 0.2610382032773647, 0.25568328654016337, 0.25538716429671415, 0.2551716957963545, 0.2550517698646668, 0.2529260759797107, 0.24521808239969511, 0.24313968506511693, 0.24062386588747078, 0.24061836651968205, 0.23952003558738638, 0.2378484705510998, 0.23635515130669854, 0.23527250969433727, 0.23289069575283183, 0.23211024548613848, 0.22404465533931667, 0.22298983996791755, 0.22149536142198623, 0.22008120624544986, 0.21918649941686433, 0.2181872336682648, 0.21683168765879704, 0.2113313962557041, 0.20818601056720137, 0.2052447390194893, 0.2048194723650316, 0.19428322037016868, 0.19289090459761762, 0.18929375401037432, 0.18735247610981667, 0.18638750778430752, 0.17955876102550708, 0.17326364960035168, 0.17070392369524612, 0.16536428697893782, 0.16067108592825263, 0.15967142329824427, 0.13142665121266, 0.1241051051982671, 0.06165999390009582, 0.021679209335556084, 0.021127025516856027, 0.007637927439532943, 0.007575066225585256, 0.005576951274531919, 0.00460872460872461, 0.0023011381500345845, 0.0019785575048732944]
  - AUC: 0.7158375
  - Precision: 0.844748858447
  - Recall: 0.4625
  - F1: 0.597738287561
================================

