preprocessSentences.py:68: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  return [clean_word(w) for w in tokens if w.lower() not in stop_words and w.isalpha()]
Path: .
Training data: ./default.txt5.train
Done building things up man. Num documents in train set: 2400.
Number of features before any feature selection: 10751
Number of features after filtering out words by count threshold: 500
Done doing the feature selection thing man. Num vocabs: 450.
Output files: ./out*
Runtime: 4.35984802246
Running model 'mybnb' on train data 'default.txt5.train' and test data 'default.txt5.test'
Num train examples = 2400, positive prior = 0.5, negative prior = 0.5
Using 450 features: dialogu, unit, music, hold, first tim, beauti, fit, wast, came, restaur...
428 features are used in positive reviews: forget, lack, month, go, friendli, send, certainli, leav, worth, case...
428 features are used in negative reviews: forget, lack, month, go, hate, friendli, send, certainli, larg, worth...
------------------------------------------------------------------------
Classifying line:
  1	Doesn't Work.	0
  words = [work]
  positive probability = 0.0262063227953, negative probability = 0.0141430948419
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  2	Unfortunately it did not work.	0
  words = [unfortun, work, unfortun work]
  positive probability = 3.62766476219e-08, negative probability = 4.89446832994e-08
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  3	All three broke within two months of use.	0
  words = [three, broke, within, two, month, use, three broke, broke within, within two, two month, month use]
  positive probability = 1.14966181868e-30, negative probability = 2.72113059429e-30
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  4	dont buy it.	0
  words = [dont, buy, dont buy]
  positive probability = 1.15163960704e-09, negative probability = 2.59118911585e-08
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  5	My father has the V265, and the battery is dying.	0
  words = [father, batteri, die, father batteri, batteri die]
  positive probability = 4.18472535858e-15, negative probability = 3.18836217797e-15
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  6	However, the ear pads come off easily and after only one week I lost one.	0
  words = [howev, ear, pad, come, easili, one, week, lost, one, howev ear, ear pad, pad come, come easili, easili one, one week, week lost, lost one]
  positive probability = 1.2535945259e-48, negative probability = 1.05156298702e-48
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  7	The calls drop, the phone comes on and off at will, the screen goes black and the worst of all it stops ringing intermittently.	0
  words = [call, drop, phone, come, screen, go, black, worst, stop, ring, intermitt, call drop, drop phone, phone come, come screen, screen go, go black, black worst, worst stop, stop ring, ring intermitt]
  positive probability = 1.38733504389e-58, negative probability = 7.35559599739e-57
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  8	Horrible, horrible protector.	0
  words = [horribl, horribl, protector, horribl horribl, horribl protector]
  positive probability = 1.99272636123e-16, negative probability = 1.6141083526e-14
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  9	I don't like this Nokia either.	0
  words = [like, nokia, either, like nokia, nokia either]
  positive probability = 3.10865312352e-14, negative probability = 4.06516177691e-14
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  10	Reaching for the bottom row is uncomfortable, and the send and end keys are not where I expect them to be.3.	0
  words = [reach, bottom, row, uncomfort, send, end, key, expect, reach bottom, bottom row, row uncomfort, uncomfort send, send end, end key, key expect]
  positive probability = 2.84869201855e-45, negative probability = 2.26312754807e-44
  predicted label = 0, expected label = 0

================================
You guessed 460/600 = 76.6666666667% correct.
  - False positive rate: [0.0, 0.2733333333333333, 1.0]
  - True positive rate: [0.0, 0.8066666666666666, 1.0]
  - Thresholds: [2, 1, 0]
  - AUC: 0.766666666667
  - Precision: 0.746913580247
  - Recall: 0.806666666667
  - F1: 0.775641025641
================================

Running model 'mymnb' on train data 'default.txt5.train' and test data 'default.txt5.test'
Num train examples = 2400, positive prior = 0.5, negative prior = 0.5
Using 450 features: dialogu, unit, music, hold, first tim, beauti, fit, wast, came, restaur...
428 features are used in positive reviews: forget, lack, month, go, friendli, send, certainli, leav, worth, case...
428 features are used in negative reviews: forget, lack, month, go, hate, friendli, send, certainli, larg, worth...
------------------------------------------------------------------------
Classifying line:
  1	Doesn't Work.	0
  words = [work]
  positive probability = 0.02, negative probability = 0.0109090909091
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  2	Unfortunately it did not work.	0
  words = [unfortun, work, unfortun work]
  positive probability = 1.46923783287e-08, negative probability = 2.00350613574e-08
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  3	All three broke within two months of use.	0
  words = [three, broke, within, two, month, use, three broke, broke within, within two, two month, month use]
  positive probability = 3.6468602659e-32, negative probability = 1.07460815835e-31
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  4	dont buy it.	0
  words = [dont, buy, dont buy]
  positive probability = 4.45223585719e-10, negative probability = 1.00175306787e-08
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  5	My father has the V265, and the battery is dying.	0
  words = [father, batteri, die, father batteri, batteri die]
  positive probability = 8.58557878798e-16, negative probability = 6.54139336227e-16
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  6	However, the ear pads come off easily and after only one week I lost one.	0
  words = [howev, ear, pad, come, easili, one, week, lost, one, howev ear, ear pad, pad come, come easili, easili one, one week, week lost, lost one]
  positive probability = 6.92694417356e-51, negative probability = 6.07593566801e-51
  predicted label = 1, expected label = 0
------------------------------------------------------------------------
Classifying line:
  7	The calls drop, the phone comes on and off at will, the screen goes black and the worst of all it stops ringing intermittently.	0
  words = [call, drop, phone, come, screen, go, black, worst, stop, ring, intermitt, call drop, drop phone, phone come, come screen, screen go, go black, black worst, worst stop, stop ring, ring intermitt]
  positive probability = 2.9185949814e-61, negative probability = 1.18309746157e-59
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  8	Horrible, horrible protector.	0
  words = [horribl, horribl, protector, horribl horribl, horribl protector]
  positive probability = 4.08837085142e-17, negative probability = 3.31158038965e-15
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  9	I don't like this Nokia either.	0
  words = [like, nokia, either, like nokia, nokia either]
  positive probability = 6.86846303038e-15, negative probability = 8.66734620501e-15
  predicted label = 0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  10	Reaching for the bottom row is uncomfortable, and the send and end keys are not where I expect them to be.3.	0
  words = [reach, bottom, row, uncomfort, send, end, key, expect, reach bottom, bottom row, row uncomfort, uncomfort send, send end, end key, key expect]
  positive probability = 2.4601033397e-47, negative probability = 1.95441543099e-46
  predicted label = 0, expected label = 0

================================
You guessed 462/600 = 77.0% correct.
  - False positive rate: [0.0, 0.27, 1.0]
  - True positive rate: [0.0, 0.81, 1.0]
  - Thresholds: [2, 1, 0]
  - AUC: 0.77
  - Precision: 0.75
  - Recall: 0.81
  - F1: 0.778846153846
================================

Running model 'bnb' on train data 'default.txt5.train' and test data 'default.txt5.test'
------------------------------------------------------------------------
Classifying line:
  1	Doesn't Work.	0
  words = [work]
  predicted label = 0.621561346309, expected label = 0
------------------------------------------------------------------------
Classifying line:
  2	Unfortunately it did not work.	0
  words = [unfortun, work, unfortun work]
  predicted label = 0.395891596211, expected label = 0
------------------------------------------------------------------------
Classifying line:
  3	All three broke within two months of use.	0
  words = [three, broke, within, two, month, use, three broke, broke within, within two, two month, month use]
  predicted label = 0.26618132372, expected label = 0
------------------------------------------------------------------------
Classifying line:
  4	dont buy it.	0
  words = [dont, buy, dont buy]
  predicted label = 0.0365215595701, expected label = 0
------------------------------------------------------------------------
Classifying line:
  5	My father has the V265, and the battery is dying.	0
  words = [father, batteri, die, father batteri, batteri die]
  predicted label = 0.53255953665, expected label = 0
------------------------------------------------------------------------
Classifying line:
  6	However, the ear pads come off easily and after only one week I lost one.	0
  words = [howev, ear, pad, come, easili, one, week, lost, one, howev ear, ear pad, pad come, come easili, easili one, one week, week lost, lost one]
  predicted label = 0.449733689084, expected label = 0
------------------------------------------------------------------------
Classifying line:
  7	The calls drop, the phone comes on and off at will, the screen goes black and the worst of all it stops ringing intermittently.	0
  words = [call, drop, phone, come, screen, go, black, worst, stop, ring, intermitt, call drop, drop phone, phone come, come screen, screen go, go black, black worst, worst stop, stop ring, ring intermitt]
  predicted label = 0.0153729815537, expected label = 0
------------------------------------------------------------------------
Classifying line:
  8	Horrible, horrible protector.	0
  words = [horribl, horribl, protector, horribl horribl, horribl protector]
  predicted label = 0.0870940933792, expected label = 0
------------------------------------------------------------------------
Classifying line:
  9	I don't like this Nokia either.	0
  words = [like, nokia, either, like nokia, nokia either]
  predicted label = 0.397961783467, expected label = 0
------------------------------------------------------------------------
Classifying line:
  10	Reaching for the bottom row is uncomfortable, and the send and end keys are not where I expect them to be.3.	0
  words = [reach, bottom, row, uncomfort, send, end, key, expect, reach bottom, bottom row, row uncomfort, uncomfort send, send end, end key, key expect]
  predicted label = 0.0971679662392, expected label = 0

================================
You guessed 464/600 = 77.3333333333% correct.
  - False positive rate: [0.0, 0.0, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.006666666666666667, 0.006666666666666667, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.016666666666666666, 0.016666666666666666, 0.02, 0.02, 0.023333333333333334, 0.023333333333333334, 0.02666666666666667, 0.02666666666666667, 0.03333333333333333, 0.03333333333333333, 0.03666666666666667, 0.03666666666666667, 0.04, 0.04, 0.043333333333333335, 0.043333333333333335, 0.06, 0.06, 0.06333333333333334, 0.06333333333333334, 0.06666666666666667, 0.06666666666666667, 0.07, 0.07, 0.07666666666666666, 0.07666666666666666, 0.07666666666666666, 0.07666666666666666, 0.09666666666666666, 0.09666666666666666, 0.1, 0.1, 0.10333333333333333, 0.10333333333333333, 0.10666666666666667, 0.10666666666666667, 0.11, 0.11, 0.11666666666666667, 0.11666666666666667, 0.12, 0.12, 0.12333333333333334, 0.12333333333333334, 0.12666666666666668, 0.13333333333333333, 0.13333333333333333, 0.13666666666666666, 0.13666666666666666, 0.14, 0.14, 0.14666666666666667, 0.14666666666666667, 0.15333333333333332, 0.15333333333333332, 0.15666666666666668, 0.15666666666666668, 0.16333333333333333, 0.16666666666666666, 0.16666666666666666, 0.17, 0.17, 0.17333333333333334, 0.17333333333333334, 0.18666666666666668, 0.18666666666666668, 0.19, 0.19, 0.19333333333333333, 0.19333333333333333, 0.2, 0.2, 0.20666666666666667, 0.20666666666666667, 0.21, 0.21, 0.21333333333333335, 0.21333333333333335, 0.21666666666666667, 0.21666666666666667, 0.23, 0.23, 0.27, 0.27, 0.2833333333333333, 0.2866666666666667, 0.2866666666666667, 0.29333333333333333, 0.29333333333333333, 0.2966666666666667, 0.2966666666666667, 0.31, 0.31, 0.31333333333333335, 0.31333333333333335, 0.32666666666666666, 0.3333333333333333, 0.34, 0.34, 0.3466666666666667, 0.3466666666666667, 0.35, 0.35, 0.3566666666666667, 0.3566666666666667, 0.37, 0.37, 0.37, 0.37, 0.39, 0.3933333333333333, 0.3933333333333333, 0.39666666666666667, 0.39666666666666667, 0.4, 0.4, 0.41333333333333333, 0.41333333333333333, 0.43333333333333335, 0.43333333333333335, 0.45666666666666667, 0.45666666666666667, 0.4866666666666667, 0.4866666666666667, 0.5, 0.5, 0.5033333333333333, 0.5133333333333333, 0.5166666666666667, 0.5166666666666667, 0.54, 0.54, 0.5433333333333333, 0.55, 0.5566666666666666, 0.5566666666666666, 0.57, 0.57, 0.5866666666666667, 0.5866666666666667, 0.6, 0.6, 0.6033333333333334, 0.6033333333333334, 0.6166666666666667, 0.6233333333333333, 0.6333333333333333, 0.6333333333333333, 0.6466666666666666, 0.6466666666666666, 0.6533333333333333, 0.66, 0.6666666666666666, 0.6666666666666666, 0.6866666666666666, 0.6866666666666666, 0.7166666666666667, 0.7233333333333334, 0.7233333333333334, 0.7366666666666667, 0.7366666666666667, 0.7433333333333333, 0.7433333333333333, 0.76, 0.76, 0.82, 0.82, 0.8333333333333334, 0.84, 0.9066666666666666, 0.9133333333333333, 0.9333333333333333, 0.94, 0.94, 0.9466666666666667, 0.9466666666666667, 0.95, 0.95, 0.99, 0.99, 1.0]
  - True positive rate: [0.0033333333333333335, 0.15, 0.15, 0.19, 0.2, 0.20666666666666667, 0.22, 0.22666666666666666, 0.23, 0.23, 0.23333333333333334, 0.23333333333333334, 0.2733333333333333, 0.29, 0.3, 0.30666666666666664, 0.31333333333333335, 0.32, 0.3566666666666667, 0.3566666666666667, 0.42, 0.4266666666666667, 0.43333333333333335, 0.43333333333333335, 0.45, 0.45, 0.4533333333333333, 0.45666666666666667, 0.4633333333333333, 0.4633333333333333, 0.4666666666666667, 0.4666666666666667, 0.49333333333333335, 0.49333333333333335, 0.5, 0.5, 0.5333333333333333, 0.5466666666666666, 0.55, 0.55, 0.5533333333333333, 0.5533333333333333, 0.5633333333333334, 0.5633333333333334, 0.57, 0.57, 0.5733333333333334, 0.5733333333333334, 0.5833333333333334, 0.59, 0.6033333333333334, 0.6033333333333334, 0.6066666666666667, 0.6066666666666667, 0.6133333333333333, 0.6133333333333333, 0.6166666666666667, 0.6166666666666667, 0.6233333333333333, 0.6233333333333333, 0.6266666666666667, 0.6266666666666667, 0.63, 0.63, 0.6333333333333333, 0.6333333333333333, 0.64, 0.6433333333333333, 0.65, 0.6533333333333333, 0.6533333333333333, 0.66, 0.66, 0.6633333333333333, 0.6633333333333333, 0.67, 0.67, 0.6833333333333333, 0.6833333333333333, 0.6933333333333334, 0.6933333333333334, 0.6933333333333334, 0.6966666666666667, 0.7, 0.7033333333333334, 0.7033333333333334, 0.7233333333333334, 0.7233333333333334, 0.7366666666666667, 0.7366666666666667, 0.74, 0.74, 0.7433333333333333, 0.7433333333333333, 0.75, 0.75, 0.7533333333333333, 0.7533333333333333, 0.76, 0.76, 0.7633333333333333, 0.7633333333333333, 0.7733333333333333, 0.7733333333333333, 0.7766666666666666, 0.81, 0.8166666666666667, 0.8166666666666667, 0.82, 0.8266666666666667, 0.8266666666666667, 0.83, 0.83, 0.8333333333333334, 0.8333333333333334, 0.8466666666666667, 0.8466666666666667, 0.85, 0.85, 0.85, 0.85, 0.8533333333333334, 0.8533333333333334, 0.8566666666666667, 0.8566666666666667, 0.86, 0.86, 0.8633333333333333, 0.8633333333333333, 0.87, 0.8766666666666667, 0.88, 0.88, 0.8833333333333333, 0.8866666666666667, 0.8866666666666667, 0.89, 0.89, 0.8933333333333333, 0.8933333333333333, 0.8966666666666666, 0.8966666666666666, 0.9033333333333333, 0.9033333333333333, 0.9066666666666666, 0.9066666666666666, 0.91, 0.91, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9233333333333333, 0.9233333333333333, 0.93, 0.93, 0.93, 0.93, 0.9333333333333333, 0.9333333333333333, 0.9366666666666666, 0.9366666666666666, 0.94, 0.94, 0.9466666666666667, 0.9466666666666667, 0.95, 0.95, 0.95, 0.95, 0.9533333333333334, 0.9533333333333334, 0.9566666666666667, 0.9566666666666667, 0.9566666666666667, 0.9566666666666667, 0.96, 0.96, 0.9633333333333334, 0.9633333333333334, 0.9633333333333334, 0.97, 0.97, 0.9733333333333334, 0.9733333333333334, 0.9766666666666667, 0.9766666666666667, 0.98, 0.98, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.99, 0.99, 0.9933333333333333, 0.9933333333333333, 0.9966666666666667, 0.9966666666666667, 1.0, 1.0]
  - Thresholds: [0.9999204162205159, 0.9622696890010962, 0.9614855325892374, 0.9509145847018227, 0.9507054809986888, 0.9497459863622263, 0.9445369294101335, 0.9442315126531206, 0.9441049374508317, 0.9429798462002515, 0.9421478730421526, 0.9421047460174999, 0.9278110481369136, 0.9243312129241396, 0.9153282757313798, 0.912804747558278, 0.9096565009954803, 0.9095544997250908, 0.8966176400964659, 0.896540800583783, 0.8596121966696348, 0.8593890307697447, 0.8587513346780049, 0.8570074272513794, 0.8493992011209855, 0.8444790711701372, 0.8419161873348586, 0.8400517320023907, 0.8326418362223056, 0.8299200012442528, 0.8281669009497651, 0.8260297457435913, 0.7928239562768621, 0.7910495242516719, 0.7861616837505939, 0.7860365532297832, 0.7587623465433676, 0.7572796411139137, 0.7531362289585802, 0.7421051882664254, 0.7415504542253907, 0.7413064393850352, 0.7361530851518984, 0.7360456166935712, 0.7343935430294858, 0.7304922113987811, 0.7277852402876956, 0.7240946557151707, 0.7140369584525396, 0.7119673034132257, 0.7036000743435546, 0.6894166519713286, 0.6828151155082384, 0.6805824726584746, 0.678787026731832, 0.6740705680759068, 0.6683922380876526, 0.6677122228681817, 0.661636292903173, 0.6577686655126633, 0.6573622974975125, 0.6492176943519219, 0.6466379145069637, 0.6407634059213897, 0.6366824925249343, 0.6341162483138895, 0.6271011577430633, 0.624125351512797, 0.6215613463088623, 0.614655161402012, 0.6111266000891685, 0.6097457204155032, 0.604238361296716, 0.6035584553412296, 0.6005764306833884, 0.598698325905978, 0.5925188325799419, 0.5838059408105146, 0.5733895310950884, 0.5688559938656542, 0.567951681693502, 0.5678362020930783, 0.5662286318681576, 0.5656028117673425, 0.5651870622229085, 0.5645666544087071, 0.543696662787846, 0.5325595366497671, 0.5206023532598496, 0.5195507403076144, 0.5185701722633239, 0.5166755478734365, 0.5152386851877687, 0.5126680461753124, 0.508104772400272, 0.5057494931267927, 0.5023128282243328, 0.49715822858603037, 0.4947098644764131, 0.4936446115558002, 0.4928860634422444, 0.4916963432118627, 0.4803056425137658, 0.4686789405720936, 0.46687767456876467, 0.46363040534654604, 0.4556622479342815, 0.4475059267572263, 0.44358643397739517, 0.43696607954395844, 0.43598098317896505, 0.43583670003910546, 0.43085505845137956, 0.4305788240834195, 0.41850997358741665, 0.4104367917270262, 0.40910351017038055, 0.40363057069714336, 0.3958915962105746, 0.3931113991707304, 0.3898222135120887, 0.3847910836641549, 0.3775012359335226, 0.3721264114944731, 0.3704505527417538, 0.3662642497468881, 0.3605669393176994, 0.36046253450785415, 0.35076024876930606, 0.35017887480453624, 0.34723465534858144, 0.34505666844525384, 0.3311622015787178, 0.3300721234110538, 0.3280388375754869, 0.3249841604845361, 0.3242564589277947, 0.32129049987394587, 0.32062230376550827, 0.313304819354092, 0.31250095692003, 0.3010658676393295, 0.29677285634732126, 0.2804416156636731, 0.2767083744507669, 0.2581140722708485, 0.2564609398491719, 0.24805151435981335, 0.23560202805503244, 0.23498533166494462, 0.23211099270458924, 0.23167127925548966, 0.22789258212427937, 0.2166598715557635, 0.2108347790525904, 0.20632935164208235, 0.2049622335652574, 0.19739211328614134, 0.1959836182097176, 0.1856205267410219, 0.17774871619940671, 0.17177315319718495, 0.16745812618021175, 0.15955160629682807, 0.15373366038338637, 0.15280466431086298, 0.1517359770816104, 0.14697707507267335, 0.14655720678072673, 0.1434135581881692, 0.1424589849141649, 0.13301055082915836, 0.13110129593891362, 0.12705145524213732, 0.12370914543700304, 0.11694184402392357, 0.11360649313956651, 0.10084492555612935, 0.09974115519914493, 0.08760584261439082, 0.08709409337918923, 0.08345135692050058, 0.07901232226937911, 0.0780018928559485, 0.07424232268675557, 0.0724061608342308, 0.06972384721009926, 0.06800023446053732, 0.04938595289743477, 0.04931104700529418, 0.04741642549618719, 0.04520178120760607, 0.024918443247617144, 0.02477670565427136, 0.018074601907868453, 0.01757835979386552, 0.017253564672586368, 0.01607911152108376, 0.015701013578844947, 0.015372981553702677, 0.01494327346570183, 0.002446863368155462, 0.0019427452636862127, 0.0010057565584028526]
  - AUC: 0.856694444444
  - Precision: 0.784722222222
  - Recall: 0.753333333333
  - F1: 0.768707482993
================================

Running model 'mnb' on train data 'default.txt5.train' and test data 'default.txt5.test'
------------------------------------------------------------------------
Classifying line:
  1	Doesn't Work.	0
  words = [work]
  predicted label = 0.636363636364, expected label = 0
------------------------------------------------------------------------
Classifying line:
  2	Unfortunately it did not work.	0
  words = [unfortun, work, unfortun work]
  predicted label = 0.400544959128, expected label = 0
------------------------------------------------------------------------
Classifying line:
  3	All three broke within two months of use.	0
  words = [three, broke, within, two, month, use, three broke, broke within, within two, two month, month use]
  predicted label = 0.211939389903, expected label = 0
------------------------------------------------------------------------
Classifying line:
  4	dont buy it.	0
  words = [dont, buy, dont buy]
  predicted label = 0.0389197776013, expected label = 0
------------------------------------------------------------------------
Classifying line:
  5	My father has the V265, and the battery is dying.	0
  words = [father, batteri, die, father batteri, batteri die]
  predicted label = 0.556116015132, expected label = 0
------------------------------------------------------------------------
Classifying line:
  6	However, the ear pads come off easily and after only one week I lost one.	0
  words = [howev, ear, pad, come, easili, one, week, lost, one, howev ear, ear pad, pad come, come easili, easili one, one week, week lost, lost one]
  predicted label = 0.486254139693, expected label = 0
------------------------------------------------------------------------
Classifying line:
  7	The calls drop, the phone comes on and off at will, the screen goes black and the worst of all it stops ringing intermittently.	0
  words = [call, drop, phone, come, screen, go, black, worst, stop, ring, intermitt, call drop, drop phone, phone come, come screen, screen go, go black, black worst, worst stop, stop ring, ring intermitt]
  predicted label = 0.0167187565925, expected label = 0
------------------------------------------------------------------------
Classifying line:
  8	Horrible, horrible protector.	0
  words = [horribl, horribl, protector, horribl horribl, horribl protector]
  predicted label = 0.011123723042, expected label = 0
------------------------------------------------------------------------
Classifying line:
  9	I don't like this Nokia either.	0
  words = [like, nokia, either, like nokia, nokia either]
  predicted label = 0.419296418708, expected label = 0
------------------------------------------------------------------------
Classifying line:
  10	Reaching for the bottom row is uncomfortable, and the send and end keys are not where I expect them to be.3.	0
  words = [reach, bottom, row, uncomfort, send, end, key, expect, reach bottom, bottom row, row uncomfort, uncomfort send, send end, end key, key expect]
  predicted label = 0.0986751211404, expected label = 0

================================
You guessed 460/600 = 76.6666666667% correct.
  - False positive rate: [0.0, 0.0, 0.0, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.006666666666666667, 0.006666666666666667, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.016666666666666666, 0.016666666666666666, 0.02, 0.02, 0.023333333333333334, 0.023333333333333334, 0.02666666666666667, 0.02666666666666667, 0.03, 0.03, 0.03333333333333333, 0.03333333333333333, 0.03666666666666667, 0.03666666666666667, 0.043333333333333335, 0.043333333333333335, 0.04666666666666667, 0.04666666666666667, 0.05, 0.05, 0.05, 0.05333333333333334, 0.05333333333333334, 0.056666666666666664, 0.056666666666666664, 0.06, 0.06, 0.06666666666666667, 0.06666666666666667, 0.07, 0.07, 0.07333333333333333, 0.07333333333333333, 0.07666666666666666, 0.07666666666666666, 0.08333333333333333, 0.08333333333333333, 0.09, 0.09, 0.09333333333333334, 0.09333333333333334, 0.09666666666666666, 0.09666666666666666, 0.1, 0.1, 0.10666666666666667, 0.10666666666666667, 0.11333333333333333, 0.11333333333333333, 0.11666666666666667, 0.11666666666666667, 0.12, 0.13, 0.13333333333333333, 0.13333333333333333, 0.14, 0.14, 0.14333333333333334, 0.14333333333333334, 0.14666666666666667, 0.15, 0.15, 0.15666666666666668, 0.15666666666666668, 0.16333333333333333, 0.16333333333333333, 0.17, 0.17, 0.18, 0.18, 0.18333333333333332, 0.18333333333333332, 0.18666666666666668, 0.18666666666666668, 0.19, 0.19, 0.19333333333333333, 0.19333333333333333, 0.19666666666666666, 0.19666666666666666, 0.2, 0.2, 0.21666666666666667, 0.21666666666666667, 0.25666666666666665, 0.2633333333333333, 0.2633333333333333, 0.26666666666666666, 0.26666666666666666, 0.28, 0.28, 0.2833333333333333, 0.2833333333333333, 0.29, 0.29, 0.2966666666666667, 0.3, 0.30333333333333334, 0.30333333333333334, 0.30666666666666664, 0.30666666666666664, 0.31666666666666665, 0.31666666666666665, 0.32, 0.32666666666666666, 0.33, 0.33, 0.35, 0.35, 0.35333333333333333, 0.35333333333333333, 0.35333333333333333, 0.35333333333333333, 0.36333333333333334, 0.36333333333333334, 0.36666666666666664, 0.36666666666666664, 0.37333333333333335, 0.37666666666666665, 0.37666666666666665, 0.38, 0.38, 0.4, 0.4, 0.41333333333333333, 0.41333333333333333, 0.4166666666666667, 0.4166666666666667, 0.43333333333333335, 0.43333333333333335, 0.44333333333333336, 0.44333333333333336, 0.44666666666666666, 0.4533333333333333, 0.4633333333333333, 0.4633333333333333, 0.48333333333333334, 0.49333333333333335, 0.49333333333333335, 0.49666666666666665, 0.49666666666666665, 0.5, 0.5033333333333333, 0.5133333333333333, 0.5133333333333333, 0.5166666666666667, 0.5233333333333333, 0.5266666666666666, 0.5266666666666666, 0.5566666666666666, 0.5566666666666666, 0.5833333333333334, 0.5833333333333334, 0.5866666666666667, 0.5866666666666667, 0.5933333333333334, 0.6, 0.6, 0.6033333333333334, 0.6033333333333334, 0.6433333333333333, 0.65, 0.6566666666666666, 0.6566666666666666, 0.66, 0.66, 0.6666666666666666, 0.6666666666666666, 0.6833333333333333, 0.6833333333333333, 0.6933333333333334, 0.6933333333333334, 0.7, 0.7066666666666667, 0.72, 0.72, 0.7366666666666667, 0.7366666666666667, 0.76, 0.76, 0.7866666666666666, 0.7866666666666666, 0.8033333333333333, 0.81, 0.85, 0.85, 0.8566666666666667, 0.8566666666666667, 0.87, 0.8766666666666667, 0.91, 0.9166666666666666, 0.93, 0.93, 0.9333333333333333, 0.9333333333333333, 0.94, 0.94, 0.95, 0.95, 0.9866666666666667, 0.9866666666666667, 1.0]
  - True positive rate: [0.0033333333333333335, 0.17333333333333334, 0.18, 0.18, 0.18333333333333332, 0.19333333333333333, 0.20666666666666667, 0.21333333333333335, 0.24, 0.24, 0.24666666666666667, 0.24666666666666667, 0.25333333333333335, 0.26666666666666666, 0.2833333333333333, 0.3, 0.31, 0.31333333333333335, 0.32, 0.36666666666666664, 0.36666666666666664, 0.39666666666666667, 0.4066666666666667, 0.41, 0.4166666666666667, 0.4166666666666667, 0.44333333333333336, 0.44666666666666666, 0.4666666666666667, 0.4666666666666667, 0.47, 0.47, 0.47333333333333333, 0.47333333333333333, 0.48, 0.48, 0.5033333333333333, 0.5166666666666667, 0.5233333333333333, 0.5233333333333333, 0.5333333333333333, 0.5333333333333333, 0.54, 0.54, 0.5433333333333333, 0.55, 0.55, 0.5566666666666666, 0.5566666666666666, 0.5633333333333334, 0.5633333333333334, 0.5666666666666667, 0.5666666666666667, 0.57, 0.57, 0.5733333333333334, 0.5733333333333334, 0.5833333333333334, 0.5833333333333334, 0.5933333333333334, 0.5933333333333334, 0.5966666666666667, 0.5966666666666667, 0.6, 0.6, 0.6066666666666667, 0.6066666666666667, 0.61, 0.61, 0.62, 0.62, 0.6233333333333333, 0.6233333333333333, 0.63, 0.6333333333333333, 0.6366666666666667, 0.6366666666666667, 0.6433333333333333, 0.6433333333333333, 0.65, 0.65, 0.6633333333333333, 0.6633333333333333, 0.67, 0.6766666666666666, 0.6766666666666666, 0.68, 0.68, 0.6866666666666666, 0.6866666666666666, 0.7, 0.7, 0.7033333333333334, 0.7033333333333334, 0.7133333333333334, 0.7133333333333334, 0.72, 0.72, 0.7333333333333333, 0.7333333333333333, 0.7366666666666667, 0.7366666666666667, 0.74, 0.74, 0.7433333333333333, 0.7433333333333333, 0.7533333333333333, 0.7533333333333333, 0.7566666666666667, 0.79, 0.79, 0.7933333333333333, 0.7933333333333333, 0.8033333333333333, 0.8033333333333333, 0.81, 0.81, 0.8133333333333334, 0.8133333333333334, 0.8166666666666667, 0.8166666666666667, 0.82, 0.82, 0.8266666666666667, 0.8266666666666667, 0.8333333333333334, 0.8333333333333334, 0.84, 0.84, 0.84, 0.84, 0.8433333333333334, 0.8433333333333334, 0.8466666666666667, 0.8466666666666667, 0.85, 0.8566666666666667, 0.86, 0.86, 0.8633333333333333, 0.8633333333333333, 0.8666666666666667, 0.8666666666666667, 0.87, 0.8733333333333333, 0.8733333333333333, 0.8766666666666667, 0.8766666666666667, 0.88, 0.88, 0.8833333333333333, 0.8833333333333333, 0.89, 0.89, 0.8933333333333333, 0.8933333333333333, 0.9, 0.9, 0.9, 0.9, 0.9033333333333333, 0.9033333333333333, 0.9033333333333333, 0.9066666666666666, 0.9066666666666666, 0.91, 0.91, 0.9133333333333333, 0.9133333333333333, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.92, 0.92, 0.9266666666666666, 0.9266666666666666, 0.93, 0.93, 0.9366666666666666, 0.9366666666666666, 0.9366666666666666, 0.94, 0.94, 0.9433333333333334, 0.9433333333333334, 0.9433333333333334, 0.9433333333333334, 0.9466666666666667, 0.9466666666666667, 0.9533333333333334, 0.9533333333333334, 0.9566666666666667, 0.9566666666666667, 0.96, 0.96, 0.9633333333333334, 0.9633333333333334, 0.9633333333333334, 0.9633333333333334, 0.9666666666666667, 0.9666666666666667, 0.97, 0.97, 0.9733333333333334, 0.9733333333333334, 0.9766666666666667, 0.9766666666666667, 0.9766666666666667, 0.9766666666666667, 0.98, 0.98, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9866666666666667, 0.9866666666666667, 0.99, 0.99, 0.9933333333333333, 0.9933333333333333, 0.9966666666666667, 0.9966666666666667, 1.0, 1.0]
  - Thresholds: [0.9999004935486208, 0.955364014106798, 0.9548340958788437, 0.9541924896841583, 0.952945654412631, 0.9528403001071811, 0.9503624775362166, 0.9502262443438916, 0.9431951882161356, 0.9399262697562857, 0.9368640751369677, 0.9368083010911719, 0.9358090185676392, 0.9318522542349525, 0.9284785435630691, 0.922929355418487, 0.9197080291970802, 0.9154087244468988, 0.915384615384615, 0.8922910680132627, 0.8915289598220133, 0.8732237574487596, 0.8698224852071004, 0.8640616028891741, 0.8623386781384439, 0.8622592803108075, 0.8513646327855947, 0.8513513513513509, 0.8331620849436211, 0.8271726862280122, 0.8200074377091852, 0.8193231960616472, 0.8153934016337848, 0.8128058146288897, 0.8023242861916612, 0.7924245629006016, 0.7752794761023418, 0.7742866303302338, 0.7716667810334186, 0.7684592012272218, 0.7639679885736691, 0.7601644586540679, 0.7579317807745831, 0.7567660325554034, 0.7523029682702151, 0.7514124293785306, 0.7510739920189267, 0.7507533068895639, 0.7504254112308564, 0.7459176735066542, 0.7449363897921888, 0.7400182898136389, 0.7373045218630204, 0.7366128269289215, 0.7306041695081406, 0.7281953021922363, 0.7274107242078084, 0.7232122583195271, 0.7229320080143645, 0.7184081917616932, 0.7106358332905178, 0.7077520663896704, 0.6940253364696287, 0.6939032714635165, 0.6929309902696932, 0.6916041311911681, 0.6909666853077495, 0.6900019214756926, 0.6899978336017772, 0.6782975544373867, 0.6697936210131332, 0.65625, 0.6554763065138135, 0.646859477232192, 0.6460009465215331, 0.6437799566920497, 0.6435814661139277, 0.6363636363636364, 0.6340227834582266, 0.6303971215877925, 0.6145729643639252, 0.5954205682843178, 0.5951584333792554, 0.5926047584564497, 0.5887850467289721, 0.5876638094218455, 0.5856345797438416, 0.578641318609911, 0.5769230769230769, 0.5740318906605917, 0.5659287776708373, 0.5599999999999999, 0.5574268578055057, 0.5485074626865671, 0.5441029450487335, 0.5440414507772019, 0.5416362304540895, 0.5385405283667956, 0.5317128354743162, 0.5257837850050664, 0.5253786742955331, 0.5231481920063675, 0.5223055665219108, 0.5217391304347824, 0.517580116797353, 0.5156224704549134, 0.5113199487398549, 0.5021349274124676, 0.5010006552924774, 0.5, 0.48625413969345843, 0.48182017344389394, 0.4767567567567565, 0.4720361882379195, 0.469086557638612, 0.46613562303506617, 0.4651665076096234, 0.4632713902701571, 0.46114864864864835, 0.4593043728394936, 0.45510835913312686, 0.44999999999999973, 0.44303797468354444, 0.4386462044869776, 0.43719671727900866, 0.43424513594970965, 0.42257217847768985, 0.42009691676873084, 0.4192964187078374, 0.4172185430463576, 0.4172185430463572, 0.41544481750766843, 0.388888888888889, 0.3874571165592831, 0.3845943725568712, 0.37451537865081364, 0.3736654804270463, 0.3723800652036099, 0.3632280298007283, 0.36011198817902446, 0.3584637268847792, 0.3551979667556916, 0.35294117647058837, 0.35294117647058804, 0.35215873571173256, 0.3515656140661675, 0.34927789891562533, 0.3394919168591224, 0.33570159857904086, 0.32206538307410404, 0.3197026869857327, 0.3147010381307273, 0.31298793470546443, 0.2980178929001066, 0.2978723404255318, 0.2897521255639849, 0.2791184900165902, 0.2763157894736841, 0.2751778360164729, 0.26698861227919035, 0.2667139656805122, 0.2541099548882745, 0.25199999999999984, 0.25084769263237167, 0.2490305324639121, 0.2464670658682635, 0.24585884863118443, 0.24179525338763946, 0.23016129433108803, 0.2295955206987937, 0.22281943970891674, 0.22261484098939924, 0.2224977308973417, 0.22118197776477463, 0.19790339031631177, 0.19334115566599303, 0.16994326248166572, 0.1686995940465841, 0.16821236405868104, 0.16227910035549895, 0.16030534351145037, 0.16030534351145023, 0.15836610578868768, 0.15709479517118524, 0.1570947951711847, 0.13469646700629972, 0.13443209299489903, 0.12414042707202295, 0.12409569851008874, 0.12296198345505722, 0.1214260071904379, 0.11917012722730502, 0.11611854310694342, 0.10512257883123784, 0.10058667198462062, 0.09681668496158051, 0.09193245778611629, 0.08763870912918893, 0.08713692946058081, 0.08265837969143756, 0.08118183073312145, 0.07764590657728757, 0.07696117445847811, 0.06872457693151676, 0.06845062552385663, 0.05815059153060845, 0.0579588870935912, 0.05154009821225072, 0.050359712230215806, 0.038251366120218504, 0.038246573178413346, 0.03657626275192829, 0.03578461771200657, 0.028700719561763562, 0.026687335037077313, 0.01984609153503441, 0.019150876481913052, 0.01487973241802068, 0.01481066118364545, 0.014279027845068976, 0.014184984974967898, 0.013203950491957895, 0.012774922589742159, 0.010591129343066342, 0.010495799273906148, 0.0013273850432325093, 0.0013133535340760108, 0.0001419482019665785]
  - AUC: 0.852705555556
  - Precision: 0.754777070064
  - Recall: 0.79
  - F1: 0.771986970684
================================

Running model 'dt' on train data 'default.txt5.train' and test data 'default.txt5.test'
Best hyperparameters were: {'max_features': 0.75, 'min_samples_leaf': 1}
------------------------------------------------------------------------
Classifying line:
  1	Doesn't Work.	0
  words = [work]
  predicted label = 0.846153846154, expected label = 0
------------------------------------------------------------------------
Classifying line:
  2	Unfortunately it did not work.	0
  words = [unfortun, work, unfortun work]
  predicted label = 0.846153846154, expected label = 0
------------------------------------------------------------------------
Classifying line:
  3	All three broke within two months of use.	0
  words = [three, broke, within, two, month, use, three broke, broke within, within two, two month, month use]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  4	dont buy it.	0
  words = [dont, buy, dont buy]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  5	My father has the V265, and the battery is dying.	0
  words = [father, batteri, die, father batteri, batteri die]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  6	However, the ear pads come off easily and after only one week I lost one.	0
  words = [howev, ear, pad, come, easili, one, week, lost, one, howev ear, ear pad, pad come, come easili, easili one, one week, week lost, lost one]
  predicted label = 1.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  7	The calls drop, the phone comes on and off at will, the screen goes black and the worst of all it stops ringing intermittently.	0
  words = [call, drop, phone, come, screen, go, black, worst, stop, ring, intermitt, call drop, drop phone, phone come, come screen, screen go, go black, black worst, worst stop, stop ring, ring intermitt]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  8	Horrible, horrible protector.	0
  words = [horribl, horribl, protector, horribl horribl, horribl protector]
  predicted label = 0.0, expected label = 0
------------------------------------------------------------------------
Classifying line:
  9	I don't like this Nokia either.	0
  words = [like, nokia, either, like nokia, nokia either]
  predicted label = 0.571428571429, expected label = 0
------------------------------------------------------------------------
Classifying line:
  10	Reaching for the bottom row is uncomfortable, and the send and end keys are not where I expect them to be.3.	0
  words = [reach, bottom, row, uncomfort, send, end, key, expect, reach bottom, bottom row, row uncomfort, uncomfort send, send end, end key, key expect]
  predicted label = 0.0, expected label = 0

================================
You guessed 446/600 = 74.3333333333% correct.
  - False positive rate: [0.0, 0.18, 0.18, 0.19666666666666666, 0.19666666666666666, 0.21, 0.21, 0.22, 0.22666666666666666, 0.25666666666666665, 0.3233333333333333, 0.3233333333333333, 0.3433333333333333, 0.36333333333333334, 0.37333333333333335, 0.37666666666666665, 0.38333333333333336, 0.41, 0.4166666666666667, 1.0]
  - True positive rate: [0.0, 0.5766666666666667, 0.62, 0.63, 0.6466666666666666, 0.6833333333333333, 0.7066666666666667, 0.7133333333333334, 0.7133333333333334, 0.7433333333333333, 0.7766666666666666, 0.78, 0.8, 0.8033333333333333, 0.8233333333333334, 0.8233333333333334, 0.8233333333333334, 0.8266666666666667, 0.8266666666666667, 1.0]
  - Thresholds: [2.0, 1.0, 0.96875, 0.8461538461538461, 0.8333333333333334, 0.8235294117647058, 0.75, 0.6666666666666666, 0.5714285714285714, 0.5, 0.4564459930313589, 0.4, 0.3333333333333333, 0.25, 0.2222222222222222, 0.16666666666666666, 0.14285714285714285, 0.1111111111111111, 0.1, 0.0]
  - AUC: 0.764044444444
  - Precision: 0.743333333333
  - Recall: 0.743333333333
  - F1: 0.743333333333
================================

Running model 'rf' on train data 'default.txt5.train' and test data 'default.txt5.test'
------------------------------------------------------------------------
Classifying line:
  1	Doesn't Work.	0
  words = [work]
  predicted label = 0.596624803322, expected label = 0
------------------------------------------------------------------------
Classifying line:
  2	Unfortunately it did not work.	0
  words = [unfortun, work, unfortun work]
  predicted label = 0.596624803322, expected label = 0
------------------------------------------------------------------------
Classifying line:
  3	All three broke within two months of use.	0
  words = [three, broke, within, two, month, use, three broke, broke within, within two, two month, month use]
  predicted label = 0.341909907019, expected label = 0
------------------------------------------------------------------------
Classifying line:
  4	dont buy it.	0
  words = [dont, buy, dont buy]
  predicted label = 0.324437903599, expected label = 0
------------------------------------------------------------------------
Classifying line:
  5	My father has the V265, and the battery is dying.	0
  words = [father, batteri, die, father batteri, batteri die]
  predicted label = 0.456233409303, expected label = 0
------------------------------------------------------------------------
Classifying line:
  6	However, the ear pads come off easily and after only one week I lost one.	0
  words = [howev, ear, pad, come, easili, one, week, lost, one, howev ear, ear pad, pad come, come easili, easili one, one week, week lost, lost one]
  predicted label = 0.447335336969, expected label = 0
------------------------------------------------------------------------
Classifying line:
  7	The calls drop, the phone comes on and off at will, the screen goes black and the worst of all it stops ringing intermittently.	0
  words = [call, drop, phone, come, screen, go, black, worst, stop, ring, intermitt, call drop, drop phone, phone come, come screen, screen go, go black, black worst, worst stop, stop ring, ring intermitt]
  predicted label = 0.0184767926089, expected label = 0
------------------------------------------------------------------------
Classifying line:
  8	Horrible, horrible protector.	0
  words = [horribl, horribl, protector, horribl horribl, horribl protector]
  predicted label = 0.435948802103, expected label = 0
------------------------------------------------------------------------
Classifying line:
  9	I don't like this Nokia either.	0
  words = [like, nokia, either, like nokia, nokia either]
  predicted label = 0.481265755742, expected label = 0
------------------------------------------------------------------------
Classifying line:
  10	Reaching for the bottom row is uncomfortable, and the send and end keys are not where I expect them to be.3.	0
  words = [reach, bottom, row, uncomfort, send, end, key, expect, reach bottom, bottom row, row uncomfort, uncomfort send, send end, end key, key expect]
  predicted label = 0.435948802103, expected label = 0

================================
You guessed 428/600 = 71.3333333333% correct.
  - False positive rate: [0.0, 0.0, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.0033333333333333335, 0.006666666666666667, 0.006666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.016666666666666666, 0.043333333333333335, 0.043333333333333335, 0.043333333333333335, 0.043333333333333335, 0.04666666666666667, 0.04666666666666667, 0.04666666666666667, 0.06, 0.06, 0.06, 0.06, 0.06333333333333334, 0.06333333333333334, 0.07666666666666666, 0.07666666666666666, 0.07666666666666666, 0.09, 0.1, 0.1, 0.1, 0.10333333333333333, 0.10333333333333333, 0.11666666666666667, 0.11666666666666667, 0.12, 0.12, 0.12, 0.12, 0.13333333333333333, 0.13666666666666666, 0.13666666666666666, 0.14, 0.14, 0.14333333333333334, 0.14333333333333334, 0.15, 0.15, 0.15, 0.15333333333333332, 0.16, 0.16, 0.16666666666666666, 0.16666666666666666, 0.17, 0.17, 0.18666666666666668, 0.18666666666666668, 0.2, 0.21, 0.21, 0.21333333333333335, 0.22333333333333333, 0.23, 0.23, 0.23, 0.23333333333333334, 0.23333333333333334, 0.23666666666666666, 0.24333333333333335, 0.25, 0.25, 0.25, 0.26, 0.26, 0.26, 0.26, 0.2733333333333333, 0.2733333333333333, 0.27666666666666667, 0.27666666666666667, 0.29, 0.5033333333333333, 0.5066666666666667, 0.5133333333333333, 0.5233333333333333, 0.53, 0.5333333333333333, 0.54, 0.5466666666666666, 0.5466666666666666, 0.5533333333333333, 0.5533333333333333, 0.5566666666666666, 0.5566666666666666, 0.5733333333333334, 0.5733333333333334, 0.5833333333333334, 0.5833333333333334, 0.59, 0.6, 0.6, 0.6066666666666667, 0.6133333333333333, 0.6166666666666667, 0.6166666666666667, 0.6233333333333333, 0.6233333333333333, 0.6366666666666667, 0.6433333333333333, 0.6433333333333333, 0.6533333333333333, 0.67, 0.6766666666666666, 0.6833333333333333, 0.6833333333333333, 0.6866666666666666, 0.6933333333333334, 0.7, 0.7, 0.7166666666666667, 0.7166666666666667, 0.7233333333333334, 0.73, 0.74, 0.74, 0.7433333333333333, 0.7433333333333333, 0.75, 0.7566666666666667, 0.7633333333333333, 0.7733333333333333, 0.7733333333333333, 0.78, 0.7833333333333333, 0.79, 0.79, 0.7933333333333333, 0.7933333333333333, 0.8, 0.8, 0.8066666666666666, 0.8366666666666667, 0.8533333333333334, 0.8633333333333333, 0.8666666666666667, 0.8666666666666667, 0.87, 0.87, 0.88, 0.8866666666666667, 0.8866666666666667, 0.89, 0.89, 0.9066666666666666, 0.9266666666666666, 0.9333333333333333, 0.9733333333333334, 0.99, 1.0]
  - True positive rate: [0.03, 0.03666666666666667, 0.13, 0.13666666666666666, 0.15666666666666668, 0.16666666666666666, 0.21333333333333335, 0.21666666666666667, 0.23666666666666666, 0.24666666666666667, 0.25333333333333335, 0.26666666666666666, 0.2733333333333333, 0.3466666666666667, 0.3933333333333333, 0.4033333333333333, 0.41333333333333333, 0.41333333333333333, 0.42, 0.4266666666666667, 0.4266666666666667, 0.43, 0.43666666666666665, 0.45, 0.45, 0.45666666666666667, 0.4633333333333333, 0.47333333333333333, 0.48, 0.48, 0.49333333333333335, 0.5033333333333333, 0.5133333333333333, 0.5133333333333333, 0.52, 0.52, 0.5233333333333333, 0.5233333333333333, 0.5266666666666666, 0.5333333333333333, 0.5366666666666666, 0.5466666666666666, 0.5466666666666666, 0.55, 0.55, 0.5566666666666666, 0.5566666666666666, 0.56, 0.56, 0.5666666666666667, 0.5733333333333334, 0.5833333333333334, 0.5833333333333334, 0.5866666666666667, 0.5866666666666667, 0.5933333333333334, 0.5933333333333334, 0.6, 0.6, 0.6066666666666667, 0.61, 0.61, 0.6233333333333333, 0.6233333333333333, 0.6233333333333333, 0.6233333333333333, 0.6266666666666667, 0.64, 0.64, 0.6433333333333333, 0.65, 0.65, 0.6566666666666666, 0.6633333333333333, 0.6666666666666666, 0.67, 0.6766666666666666, 0.6833333333333333, 0.69, 0.6933333333333334, 0.6966666666666667, 0.6966666666666667, 0.7033333333333334, 0.71, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.8333333333333334, 0.8333333333333334, 0.8366666666666667, 0.84, 0.8466666666666667, 0.8466666666666667, 0.85, 0.85, 0.8533333333333334, 0.8533333333333334, 0.8633333333333333, 0.8633333333333333, 0.8666666666666667, 0.8733333333333333, 0.8733333333333333, 0.8733333333333333, 0.8733333333333333, 0.88, 0.88, 0.89, 0.8966666666666666, 0.8966666666666666, 0.9, 0.9, 0.9, 0.9033333333333333, 0.9033333333333333, 0.91, 0.9133333333333333, 0.92, 0.92, 0.9233333333333333, 0.9233333333333333, 0.9266666666666666, 0.94, 0.94, 0.94, 0.9433333333333334, 0.9433333333333334, 0.9466666666666667, 0.9466666666666667, 0.9466666666666667, 0.95, 0.95, 0.9566666666666667, 0.96, 0.9633333333333334, 0.9633333333333334, 0.9666666666666667, 0.9666666666666667, 0.97, 0.97, 0.9766666666666667, 0.98, 0.98, 0.98, 0.98, 0.9833333333333333, 0.9866666666666667, 0.9866666666666667, 0.99, 0.99, 0.99, 0.9933333333333333, 0.9933333333333333, 0.9966666666666667, 0.9966666666666667, 0.9966666666666667, 0.9966666666666667, 1.0, 1.0, 1.0]
  - Thresholds: [0.9688827817314829, 0.9615404869772509, 0.9609346362802407, 0.9566952174298099, 0.9489336659190661, 0.9406295404030761, 0.9401456694353343, 0.8784713084351, 0.8748651308289225, 0.7900137685165464, 0.784034839174832, 0.7624516512149583, 0.7615744035661852, 0.7600372414040231, 0.675759959861487, 0.6741432587871883, 0.6656314564036434, 0.6600388589322688, 0.6531263116952417, 0.6349156832305042, 0.6159117166582679, 0.612629612776672, 0.6112248253149596, 0.6092457878213725, 0.6082137157487182, 0.6013682198811469, 0.596624803322206, 0.5913788724681274, 0.5897975638438553, 0.5831333807780302, 0.5812195051799441, 0.5777050927630927, 0.5738124464565534, 0.5698379548682304, 0.562821976795538, 0.5471669200469412, 0.5470932482244719, 0.5396747893276665, 0.5339611414143699, 0.5333075810496092, 0.5325307187442807, 0.529207223558151, 0.5267894118741814, 0.5243736499940123, 0.5241013437855269, 0.5178263964835632, 0.5169991915823916, 0.5169959288088571, 0.5126138593766203, 0.5086655872417446, 0.508315272995641, 0.5079739743500304, 0.5075157338962398, 0.5066710372561795, 0.5058731340138961, 0.5022610072065801, 0.5019909994718144, 0.49909567089494933, 0.49007752920285946, 0.4862984758978083, 0.4812657557424451, 0.4711847737012935, 0.4709174588374989, 0.46907365442200144, 0.4686816074420077, 0.46803865582527904, 0.46785978543654627, 0.46767051103590496, 0.46762769144864313, 0.4662612231401142, 0.465809371582163, 0.46163032775634494, 0.46021386135175146, 0.4574998426287463, 0.4574766219075796, 0.45623340930314604, 0.4551347143145597, 0.4545826053340747, 0.4525287131694995, 0.4473353369686254, 0.4432960252093208, 0.4418281347490086, 0.4411075343045115, 0.4361442735894232, 0.43594880210281056, 0.43324321798027193, 0.43275303333046256, 0.43031962833058235, 0.4301782079807602, 0.42622585916271005, 0.4258365906243952, 0.4239074260162829, 0.4232412981220687, 0.4216251367028904, 0.42060959689852384, 0.41910298722036876, 0.4189554444112465, 0.41335478842105167, 0.41247196093026856, 0.4049307408953648, 0.39946492919913473, 0.39436939288090644, 0.39290660080215306, 0.38979303600870474, 0.38721223290071266, 0.38575895717020603, 0.3852539100767725, 0.3835004301370073, 0.38220756289737595, 0.3739273719598539, 0.37332389438258123, 0.37316923657003204, 0.3715847959717981, 0.3712156616650696, 0.36165082566201856, 0.35978830182352367, 0.35762647364252514, 0.35324586094451904, 0.35067325807015265, 0.34993186834813406, 0.3486900941720878, 0.3477498210986036, 0.3379882583611194, 0.33763669601438273, 0.3374712956635243, 0.3347337859114205, 0.3321446952885978, 0.33110333156799526, 0.3306879806060746, 0.3303572842496768, 0.3293457788691361, 0.325893855792213, 0.32522608415354, 0.3244379035990212, 0.31234272377343114, 0.2984571038558158, 0.2961236253013486, 0.2941141636423781, 0.2912162795168515, 0.28879011502971047, 0.28766360684714853, 0.2860590360446911, 0.2852299011062861, 0.2808622195807017, 0.25699430582845034, 0.2350767045994145, 0.23097527909916424, 0.22516363185310811, 0.2226080749380624, 0.20944570033923018, 0.20382291931688676, 0.1706026417107649, 0.14831529183227288, 0.12404092567150217, 0.10499471243979479, 0.10094139429260127, 0.06143319762946767, 0.060521167054888234, 0.04766822266008706, 0.045256987717873766, 0.009743589743589744, 0.0028985097151480854]
  - AUC: 0.781622222222
  - Precision: 0.778260869565
  - Recall: 0.596666666667
  - F1: 0.675471698113
================================

