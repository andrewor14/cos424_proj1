\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Dataset}{1}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Data processing}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Feature extraction}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Feature selection}{2}{subsection.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Classification}{3}{section.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A complex decision tree, borrowed from []}}{3}{figure.1}}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluation}{4}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Metrics}{4}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Hyperparameter tuning}{4}{subsection.5.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Accuracy, precision, recall, F1 score, and area under ROC curve for all models evaluated under two datasets of different sizes using 5-fold cross validation. \texttt  {mybnb} and \texttt  {mymnb} refer to the custom implementation of Bernoulli naive Bayes and multinomial naive Bayes respectively. The rest of the classifiers use implementations provided by \texttt  {scikit-learn}.}}{5}{table.1}}
\newlabel{tab:classifiers}{{1}{5}{Accuracy, precision, recall, F1 score, and area under ROC curve for all models evaluated under two datasets of different sizes using 5-fold cross validation. \texttt {mybnb} and \texttt {mymnb} refer to the custom implementation of Bernoulli naive Bayes and multinomial naive Bayes respectively. The rest of the classifiers use implementations provided by \texttt {scikit-learn}}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Results}{5}{subsection.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6}BLARGH}{5}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Evaluation}{5}{subsection.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Results}{6}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Evaluation results}{6}{subsection.7.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces {\bf  Top $10$ predictive words for each of the 20 Newsgroups.} The top ten words were identified after feature selection from a fitted random forest classifier using words ranked by their Gini impurity scores.}}{6}{table.2}}
\newlabel{tab:words}{{2}{6}{{\bf Top $10$ predictive words for each of the 20 Newsgroups.} The top ten words were identified after feature selection from a fitted random forest classifier using words ranked by their Gini impurity scores}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Computational speed}{6}{subsection.7.2}}
\citation{zhu2009}
\citation{lacoste2009}
\bibdata{ref}
\bibstyle{plos2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Feature selection}{7}{subsection.7.3}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Discussion and Conclusion}{7}{section.8}}
\@writefile{toc}{\contentsline {section}{\numberline {9}References?}{7}{section.9}}
